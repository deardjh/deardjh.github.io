<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[多任务学习|深层神经网络中的多任务学习研究综述]]></title>
    <url>%2F2019%2F04%2F27%2Fmutiltask-introduction%2F</url>
    <content type="text"><![CDATA[目录# 引言#在机器学习(ML)中，我们通常关心的是针对特定指标的优化，无论这是某个基准上的得分还是业务KPI。为了做到这一点，我们通常训练一个模型或一组模型来执行我们想要的任务。然后，我们对这些模型进行微调和调整，直到它们的性能不再增加。虽然我们通常可以通过这种方式达到可接受的表现，通过专注于我们的单一任务，我们忽略了那些可能帮助我们在我们关心的指标上做得更好的信息。具体来说，这些信息来自于相关任务的训练信号。通过在相关任务之间共享表示，我们可以使模型更好地概括原始任务。这种方法被称为多任务学习(MTL)，将是本文的主题。 从自然语言处理[1]和语音识别[2]到计算机视觉[3]和药物发现[4]，多任务学习已经成功地应用于机器学习的所有应用中。Mtl有多种形式:联合学习、学会学习、辅助任务学习，这些只是被用来指代它的一些名称。 即使只是优化一个损失的情况下，也会有一个辅助任务，将帮助改善你的主要任务。RichCaruana[5]简洁地总结了MTL的目标:“MTL通过利用相关任务的训练信号中包含的领域特定信息来提高泛化能力”。 我将首先从不同的角度来激励MTL。然后，我将介绍深度学习中MTL最常用的两种方法。随后，我将描述一些机制，一起说明为什么MTL在实践中起作用。在研究更先进的基于神经网络的MTL方法之前，我将通过讨论MTL中的文献来提供一些上下文。然后，我将介绍一些更强大的最近提出的方法MTL在深度神经网络。最后，我将介绍常用的辅助任务类型，并讨论如何为MTL提供一个好的辅助任务。 动机#我们可以用不同的方式来激励多任务学习:-从生物学的角度来说，我们可以把多任务学习看作是受到人类学习的启发。在学习新任务时，我们经常应用通过学习相关任务获得的知识。例如，婴儿首先学会识别面孔，然后可以应用这些知识识别其他物体。 -从教学的角度来看，我们通常首先学习任务，这些任务为我们提供了掌握更复杂技巧的必要技能。这对于学习正确的摔跤方式来说是正确的，例如柔道和编程。举个流行文化的例子，我们也可以看看《功夫梦》(1984),在电影中，宫城先生教空手道小子一些看似无关的任务，比如打磨地板和给汽车打蜡。然而，事后看来，这些东西反而使他具备了学习空手道相关的宝贵技能。 -最后，我们可以从机器学习的角度来激励多任务学习:我们可以把多任务学习看作是一种归纳迁移。归纳转移可以通过引入一种归纳偏见来帮助改进一个模型，这种偏见会导致一个模型偏好某些假设而非其他假设。例如，归纳偏差的一种常见形式是l1正则化，这导致了对稀疏解的偏好。在MTL的情况下，辅助任务提供了归纳偏差，导致模型偏好解释一个以上任务的假设。正如我们将很快看到的，这通常会导致更好地概括的解决方案。 深度学习的两种MTL方法#硬参数共享#硬参数共享是神经网络中最常用的MTL方法，可以追溯到[6]。它的应用通常是在所有任务之间共享隐藏层，同时保留几个特定于任务的输出层。 硬参数共享大大降低了过拟合的风险。事实上，[7]表明，过度拟合共享参数的风险是一个顺序n——其中n是任务数量:小于过度拟合任务特定参数，即输出层。这在直觉上是有道理的:我们同时学习的任务越多，我们的模型就越需要找到一个能够捕捉所有任务的表示，我们对原始任务的过度适应的机会就越少。 软参数共享#在软参数共享中，每个任务都有自己的模型和参数。然后对模型参数之间的距离进行正则化，以使参数相似。例如，使用l2范数进行正则化，而[9]使用跟踪范数。 深层神经网络中用于软参数共享的约束条件受到了MTL正则化技术的极大启发，这些技术已经在其他模型中得到发展，我们将很快讨论。 为什么MTL有效#尽管通过多任务学习获得的归纳偏差在直觉上似乎是可信的，但为了更好地理解MTL，我们需要研究其背后的机制。其中大多数最早由Caruana(1998)提出。对于所有的例子，我们假设我们有两个相关的tasksAa和bb，它们依赖于一个公共的隐藏层表示f。 隐式数据增强#Mtl有效地增加了我们用来训练模型的样本量。 由于所有的任务都至少有些嘈杂，当我们在taskAa上训练一个模型时，我们的目标是学习任务a的一个很好的表示，理想地忽略数据相关的噪声，并且很好地进行概括。由于不同的任务具有不同的噪声模式，一个同时学习两个任务的模型能够学习更一般的表示。只学习任务a承担了任务a过度拟合的风险，而学习a和b共同使模型通过平均噪声模式得到更好的表示f。 注意力集中#如果一个任务是非常嘈杂的，或者数据是有限的和高维的，那么模型很难区分相关的和不相关的特征。Mtl可以帮助模型将注意力集中在那些真正重要的特性上，因为其他任务将为这些特性的相关性或不相关性提供额外的证据。 窃听#对于某些任务b来说，g很容易学习，而对于另一个任务a来说，g很难学习。这可能是因为a以一种更复杂的方式与特性交互，或者是因为其他特性阻碍了模型学习g的能力。通过MTL，我们可以允许模型窃听，即通过任务b学习g。最简单的方法是通过提示[10]，即直接训练模型来预测最重要的特征。 表征偏见#Mtl 使模型偏向于其他任务也喜欢的表示形式。这也将有助于模型推广到未来的新任务中，作为一个假设空间，这个空间在一个足够大的训练任务中表现良好，在学习新任务时也表现良好，只要它们来自相同的环境[11]。 正则化#Mtl起到了正则化的作用,因为他降低了过拟合的风险以及模型Rademacher复杂性,即他适应随机噪声的能力 非神经模型中的 MTL#为了更好地理解深层神经网络中的 MTL，我们现在将查看现有的文献中的线性模型，核方法和贝叶斯算法 MTL。 特别是，我们将讨论在多任务学习的历史中普遍存在的两个主要观点: 通过规范化实现任务之间的稀疏性; 以及建立任务之间的关系模型。 块(组)稀疏正则化#请注意，文献中的许多 MTL 方法都处理同构设置: 它们假设所有任务都与单一输出相关，例如，多类 MNIST 数据集通常被转换为10个二进制分类任务。 最近的方法处理更加现实的、异构的设置，其中每个任务对应于一组唯一的输出。 现有的许多方法对模型参数做了一些稀疏性假设。 [12]假设所有型号共享一小部分特性。 就我们的任务参数 matrixA a 而言，这意味着除了少数行之外，所有行都是00，这只对应于所有任务中使用的少数特性。 为了加强这一点，他们将 l1 l1规范推广到 MTL 设置。 回想一下，l1 l1范数是参数总和的约束，它强制除了少数几个参数之外的所有参数都精确地为00 尽管这种块稀疏的正则化在直观上是合理的，但它非常依赖于任务之间共享特性的程度。 [16]表明，如果特征不重叠很多，l 1 / l q l1 / lq 正则化实际上可能比元素级 l1 l1正则化更糟糕。 学习任务关系#虽然组稀疏性约束迫使我们的模型只考虑少数特性，但这些特性主要用于所有任务。 所有以前的方法都假定多任务学习中使用的任务是密切相关的。 但是，每个任务可能并不与所有可用的任务密切相关。 在这种情况下，与一个不相关的任务分享信息实际上可能会损害表现，这种现象被称为负迁移。 因此，我们希望利用先前的知识来表明某些任务是相关的，而其他任务则不是。 在此场景中，强制执行任务集群的约束可能更合适。 建议通过处罚我们的任务列矢量alpha1,alpha2….以及他们与以下约束的差异，来强加一个聚类约束 $$\Omega=|\bar{a}|^2+\dfrac{\lambda}{T}\sum^T_{t=1}|a_{\cdot,t}-\bar{a}|^2$$ 以前的任务关系建模方法采用规范化，其他方法没有规范化: [24]是第一个提出使用 k 近邻的任务聚类算法的方法，而[25]从多个相关任务中学习共同的结构，并应用到半监督学习。 在多任务学习的任务关系学习的许多其他工作使用贝叶斯方法: [26]提出了一个多任务学习的贝叶斯神经网络通过放置一个先验的模型参数，以鼓励类似的参数跨任务。 通过推导共享协方差矩阵的参数，将高斯过程(GP)扩展到 MTL。 由于这是非常昂贵的计算，他们采取了一个稀疏近似方案，贪婪地选择最有价值的例子。 通过假设所有模型都是从一个共同的先验中取样，也可以将 GP 用于 MTL。 将高斯分布作为每个任务特定层的先验分布。 为了鼓励不同任务之间的相似性，他们提出使平均任务依赖，并引入混合分布的任务聚类。 重要的是，它们需要任务特征来定义集群和需要预先指定的混合物数量。 其他方法侧重于在线多任务学习设置: [33]调整一些现有的方法，如 Evgeniou 等人(2005)的方法，以适应在线设置。 他们还提出了正则化感知器的 MTL 扩展，将任务相关性编码在矩阵中。 他们使用不同的正则化形式来偏置这个任务关联矩阵，例如任务特征向量的贴近度或者跨越子空间的维数。 重要的是，与以前的一些方法类似，它们要求提前提供构成这个矩阵的任务特征。 然后通过学习任务关系矩阵来扩展先前的方法。 反过来，通过假设存在少量潜在的基本任务，允许来自不同组的两个任务重叠。 然后，他们将每个实际任务 t 的参数矢量 t 建模为这样一个线性组合: 在 Lst 处的参数矢量 t 是包含 k 个潜在任务的参数向量的矩阵，而 st ∈ r k st ∈ r k 是包含线性组合系数的向量。 此外，它们还限制潜在任务中的线性组合分布为稀疏; 两个任务之间稀疏模式的重叠控制了这些任务之间的共享量。 最后，[37]学习一小组共享的假设，然后将每个任务映射到一个单一的假设。 最近关于深度学习的 MTL 的工作#虽然最近许多深度学习方法都使用了多任务学习——无论是显式的还是隐式的——作为他们模型的一部分(下一节将介绍突出的例子) ，但是他们都使用了我们前面介绍的两种方法，硬参数和软参数共享。 相比之下，只有少数几篇论文着眼于在深层神经网络中开发更好的 MTL 机制。 深层关系网络 1在计算机视觉的 MTL 中，各种方法通常共享卷积层，而学习任务特定的完全连接层。 通过提出深层关系网络来改进这些模型。 除了图3中显示的共享层和特定任务层的结构之外，它们还在完全连接的层上放置矩阵先验，这使得模型能够学习任务之间的关系，类似于我们之前看到的一些贝叶斯模型。 然而，这种方法仍然依赖于一种预先定义的共享结构，这种结构可能足以解决经过充分研究的计算机视觉问题，但是对于新任务来说很容易出错。 完全自适应的特征共享 1从另一个极端开始，[39]提出了一种自下而上的方法，这种方法从一个薄的网络开始，在训练过程中使用一种标准，促进类似任务的分组，贪婪地扩大网络。 动态创建分支的 widing 过程可以在图4中看到。 然而，贪婪的方法可能无法发现一个全局最优的模型，而分配每个分支到一个任务却不允许模型学习任务之间更复杂的交互。 十字绣网络 1[40]从两个独立的模型结构开始，就像软参数共享一样。 然后，他们使用所谓的十字绣单元，让模型决定以何种方式特定任务的网络利用其他任务的知识，通过学习前面各层的输出线性组合。 他们的架构可以在图5中看到，其中他们只放置十字绣单位后，池和完全连接的层。 低层监督 1相比之下，在自然语言处理(NLP)中，最近的工作集中于**为多任务学习寻找更好的任务层次结构**:[41]表明，低层任务，即通常用于预处理的 NLP 任务，如词性标注和命名实体识别，当用作辅助任务时，应该在较低层进行监督。 联合多任务模型 1基于这一发现，[42]预先定义了一个由几个 NLP 任务组成的层次结构，如图6所示，作为多任务学习的联合模型。 以不确定性加权亏损 1与其学习共享的结构，[43]考虑每个任务的不确定性，采取一种正交的方法。 然后通过推导基于任务相关不确定性最大高斯似然的多任务损失函数来调整每个任务在成本函数中的相对权重。 它们用于逐像素深度回归、语义分割和实例分割的体系结构如图7所示。 Mtl 的张量因子分解 1最近的工作试图将现有的 MTL 方法推广到深度学习: [44]将前面讨论过的一些矩阵分解方法推广到使用张量分解将模型参数分解为每一层的共享参数和任务特定参数。 水闸网络 1最后，我们提出了一个概括了基于深度学习的 MTL 方法的模型，例如硬参数共享和跨缝网络，块稀疏正则化方法，以及最新的自然语言处理方法来创建一个任务层次。 这个模型，如图8所示，允许学习哪些层和子空间应该被共享，以及在哪些层网络已经学习了输入序列的最佳表示。 我应该在我的模型中分享什么？#Mtl 历史上的大多数方法都集中在任务从相同分布中提取的场景上(Baxter，1997)。 虽然这种情况有利于共享，但并不总是成立。 因此，为了开发 MTL 的健壮模型，我们必须能够处理不相关或只是松散相关的任务。 虽然针对深度学习的 MTL 的早期工作已经预先指定了每个任务配对应该共享哪些层，但是这种策略并不具有可伸缩性，而且严重偏向 MTL 架构。 最初由 Caruana (1996)提出的硬参数共享技术，在20年后仍然是标准技术。 虽然在许多场景中很有用，但如果任务之间没有密切关系或者需要在不同层次上进行推理，硬参数共享就会很快崩溃。因此，最近的方法着眼于了解应该分享什么，并且通常比硬参数分享更有效。 此外，赋予我们的模型学习任务层次结构的能力是有帮助的，特别是在需要不同粒度的情况下。 正如最初提到的，我们正在做 MTL 尽快我们是优化一个以上的损失函数。 与其限制我们的模型将所有任务的知识压缩到相同的参数空间中，不如利用我们已经讨论过的 MTL 的先进技术，使我们的模型能够了解任务之间应该如何相互作用。 什么辅助任务是有帮助的？#在本节中，我们讨论了不同的辅助任务，这些辅助任务可用于利用 MTL，即使我们只关心一个任务。 然而，我们仍然不知道什么辅助任务在实践中是有用的。 辅助任务的发现在很大程度上是基于这样的假设，即辅助任务应该以某种方式与主任务相关，并且辅助任务应该有助于预测主任务。 然而，我们仍然不清楚两个任务何时应该被认为是相似或相关的。 Caruana (1998)将两个任务定义为相似的，如果它们使用相同的特性来做决定。 Baxter (2000)只在理论上认为相关任务具有共同的最优假设类，即具有相同的归纳偏差。 如果两个任务的数据都可以使用一组转换f从一个固定的概率分布生成，那么 areF 提出的两个任务是相关的。 虽然这样可以推理出不同传感器为同一分类问题收集数据的任务，例如用不同角度和光照条件的摄像机数据进行物体识别，但不适用于不处理同一问题的任务。 薛等人(2007)最后提出，如果两个任务的分类边界是相似的，即参数向量是相近的。 尽管在理解任务相关性方面取得了这些早期的理论进展，但是我们在实现这一目标方面还没有取得很大的进展。 任务相似性不是二进制的，而是存在于一个范围内的。 更多类似的任务应该对 MTL 有更多帮助，而较少类似的任务应该帮助较少。 允许我们的模型学习与每个任务分享什么，可能会让我们暂时绕过理论的缺乏，更好地利用甚至只是松散相关的任务。 然而，我们也需要在多任务学习方面发展一个更有原则的任务相似性概念，以便知道我们应该更喜欢哪些任务。 最近的工作[55]发现，对于 NLP 中的序列标签问题，具有紧凑和均匀标签分布的辅助任务更为可取，我们已经在实验中证实了这一点(Ruder 等人，2017)。 此外，研究发现，主要任务在非停滞的辅助任务中很可能很快停滞不前[56]。 然而，这些实验到目前为止在范围上还是有限的，最近的发现仅仅提供了对神经网络中的多任务学习进行更深入理解的第一线索。 总结#在这篇综述中，我回顾了多任务学习的文献历史以及最近关于深度学习的 MTL 的工作。 虽然 MTL 正在被越来越频繁的使用，20年前的硬参数共享范例仍然是普遍的神经网络为基础的 MTL。 然而，在学习分享什么方面的最新进展是有希望的。 与此同时，我们对任务的理解—-它们的相似性、关系、层次以及对 MTL 的好处—-仍然是有限的，我们需要更多地了解它们，以便更好地理解 MTL 相对于深层神经网络的泛化能力。 参考# rudermutil-task]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>MutilTaskLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP | BERT]]></title>
    <url>%2F2019%2F04%2F15%2Fbert_basic%2F</url>
    <content type="text"><![CDATA[目录# Intro Pre-trained models Fine-tuning with BERT Sentence (and sentence-pair) classification tasks Related Intro#《Pre-training of Deep Bidirectional Transformers for Language Understanding》 Pre-training language representations. Pre-trained representations can also either be context-free or contextual, and contextual representations can further be unidirectional or bidirectional. Unsupervised BERT was trained using only a plain text corpus BERT uses a simple approach for this: We mask out 15% of the words in the input, run the entire sequence through a deep bidirectional Transformer encoder, and then predict only the masked words. 12Input: the man went to the [MASK1] . he bought a [MASK2] of milk.Labels: [MASK1] = store; [MASK2] = gallon paper google bert pytorch_pretrained_bert convert_tf_checkpoint_to_pytorch 12https://blog.csdn.net/qq_28168421/article/details/84038811python convert_tf_checkpoint_to_pytorch.py --tf_checkpoint_path chinese_L-12_H-768_A-12/bert_model.ckpt --bert_config_file chinese_L-12_H-768_A-12/bert_config.json --pytorch_dump_path chinese_L-12_H-768_A-12/bert_chinese.pth BERT, or Bidirectional Encoder Representations from Transformers, is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks. Using BERT has two stages: Pre-training and fine-tuning. Pre-training is fairly expensive (four days on 4 to 16 Cloud TPUs), but is a one-time procedure for each language (current models are English-only, but multilingual models will be released in the near future). We are releasing a number of pre-trained models from the paper which were pre-trained at Google. Most NLP researchers will never need to pre-train their own model from scratch. Fine-tuning is inexpensive. All of the results in the paper can be replicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU, starting from the exact same pre-trained model. SQuAD, for example, can be trained in around 30 minutes on a single Cloud TPU to achieve a Dev F1 score of 91.0%, which is the single system state-of-the-art. The other important aspect of BERT is that it can be adapted to many types of NLP tasks very easily. If you already know what BERT is and you just want to get started, you can download the pre-trained models and run a state-of-the-art fine-tuning in only a few minutes. pre-trained models fine-tuning-with-bert Pre-trained models# Each .zip file contains three items: A TensorFlow checkpoint (bert_model.ckpt) containing the pre-trained weights (which is actually 3 files).A vocab file (vocab.txt) to map WordPiece to word id.A config file (bert_config.json) which specifies the hyperparameters of the model. Fine-tuning with BERT#The fine-tuning examples which use BERT-Base should be able to run on a GPU that has at least 12GB of RAM using the hyperparameters given. # Before running this example you must download the GLUE data by running this script and unpack it to some directory $GLUE_DIR. Next, download the BERT-Base checkpoint and unzip it to some directory $BERT_BASE_DIR. Glue Datasets BERT之’测试数据集描述’ Related# 一文读懂BERT中的WordPiece BERT 详解]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>BERT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python | 更加Pythonic的编程习惯]]></title>
    <url>%2F2019%2F04%2F08%2Fpythonic%2F</url>
    <content type="text"><![CDATA[目录# 交换赋值 解包 Unpacking 判断条件 遍历 列表推导 排列组合 中间结果尽量使用imap/ifilter代替map/filter 变量类型判断 any()和all() 字典 字符串 调试 交换赋值#1a,b = b,a 解包 Unpacking#123a,b,c = (1,2,3)a,b,c = [1,2,3]a,b,c = &#123;1,2,3&#125; 判断条件#123456789对象用 is一般变量用 ==或者if obj: passif x: pass 遍历#12345678910for i,x in enumerate(lst): passfor x,y in zip(lst1,lst2): pass x=[]y=[]z=[]for i,j,k in itertools.produc(x,y,z):# 笛卡尔积 print(i,j,k) 列表推导#12[fn(x) for lst in lsts if condition(lst)\ for x in lst if condition(x)] 排列组合#1234import itertoolsitertools.permutations([1,2,3],2)itertools.permutations([1,2,3,4],2)itertools.combinations([1,2,3],2) 中间结果尽量使用imap/ifilter代替map/filter#123from itertools import ifilter, imapreduce(rf, ifilter(ff, imap(mf, a_list)))#lazy evaluation 会带来更高的内存使用效率，特别是当处理大数据操作的时候 变量类型判断#1234#判断变量num是否为整数类型type(num) == type(0) #调用三次函数type(num) is type(0) #身份比较isinstance(num,(int)) #调用一次函数 any()和all()#123456789101112##不推荐found = Falsefor item in a_list: if condition(item): found = True breakif found: # do something if found... ##推荐if any(condition(item) for item in a_list): # do something if found... 字典#123456dct=&#123;&#125;键值列表：dct #不推荐dct.keys()键值判断： if key in dct #不推荐dct.keys() 或者 dct.has_key(key)取值：dct.get('key','') #不推荐dct['key']设值：dict.setdefault(key, default=None)#不推荐 dct[key]='' 字符串#12345678910111213141516171819202122232425262728旧格式%：#Python 3.6之前,易读性差 print("%s is %.2f"%(a,b))新格式.format：#Python 3.6之前,易读性提高，但是参数比较多的情况下显得冗长 person = &#123;'name': 'Eric', 'age': 74&#125; print("&#123;&#125; is &#123;:.2f&#125;".format(a,b)) "Hello, &#123;1&#125;. You are &#123;0&#125;-&#123;0&#125;.".format(age, name) "Hello, &#123;name&#125;. You are &#123;age&#125;.".format(name=person['name'], age=person['age'])f-Strings：#Python 3.6之后，运行时渲染,速度更快，更简洁 name = "Eric" age = 74 f"Hello, &#123;name&#125;. You are &#123;age&#125;." F"Hello, &#123;name&#125;. You are &#123;age&#125;." f"&#123;2 * 37&#125;" f"&#123;name.lower()&#125; is funny." f"&#123;'Eric Idle'&#125;" f"&#123;&#123;74&#125;&#125;" #&#123;74&#125; 注意字典中key的引号与f-string的引号要区别 圆括号解决lambda表达式冒号困扰 f"&#123;(lambda x: x * 37) (2)&#125;"多行f-string： message = (f"Hi &#123;name&#125;. " f"You are a &#123;profession&#125;. " f"You were in &#123;affiliation&#125;.") f""" Hi &#123;name&#125;. You are a &#123;profession&#125;. You were in &#123;affiliation&#125;. """ 调试#123456789101112131415pdb #Python3.7之前 可以单步调试：python -m pdb xxx.py 太麻烦 可以在脚本中编写 1.import pdb 2.添加pdb.set_trace()到可能出错的代码前面 # test1.py import pdb s = '0' n = int(s) pdb.set_trace() #运行到这里会自动暂停 print(10/n)breakpoint()#Python3.7之后Web-PDB：在内置 PDB 上增加了 web 界面，并允许在 web 浏览器中远程调试 Python 脚本, 需要安装pip install web-pdb]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DL | 模型训练技巧]]></title>
    <url>%2F2019%2F04%2F08%2Fmodel_training_tips%2F</url>
    <content type="text"><![CDATA[目录# 数据 数据扩增 数据划分 预处理 模型训练 运行时设置可见GPU CUDA_VISIBLE_DEVICES 训练技巧 模型参数初始化 超参数调试 params 观察模型参数更新幅度(程度) 批处理大小 batch_size 学习率 learning_rate 偏置与方差 bias &amp; variance 查看GPU状态 gpustat 优化算法 性能提升 测评 参考 数据#数据扩增#数据划分#12345678910数据总量在十万级别 train,test = 0.7,0.3 train,dev,test = 0.6,0.2,0.2 确保分布大致相同数据总量在百万级别 通常会倾向与划分更小比例的数据到devset和testset。 划分devset的目标是校验模型并且调整以及选择一个最佳的模型； 划分test set的目标是评估最优模型的性能。所以，不必要划分太多的数据到这两个数据集上 分别划分dev,test=10000,10000 就足够了 确保分布大致相同 预处理#模型训练#运行时设置可见GPU CUDA_VISIBLE_DEVICES#123CUDA_VISIBLE_DEVICES=1 只有编号为1的GPU对程序是可见的，在代码中gpu[0]指的就是这块儿GPUCUDA_VISIBLE_DEVICES=0,2,3 只有编号为0,2,3的GPU对程序是可见的，在代码中gpu[0]指的是第0块儿，gpu[1]指的是第2块儿，gpu[2]指的是第3块儿CUDA_VISIBLE_DEVICES=2,0,3 只有编号为0,2,3的GPU对程序是可见的，但是在代码中gpu[0]指的是第2块儿，gpu[1]指的是第0块儿，gpu[2]指的是第3块儿 训练技巧#121.先训练一小部分数据来验证模型有没有异常，确认模型可以对这小部分数据过拟合，即对这小部分数据的预测达到100%准确，这样的话就验证了我们的反向传播算法等等是正确的，然后就可以开始训练大量数据。如果过拟合都无法做到，更别提大量数据下的拟合了。2.绘制训练过程中的损失函数，以及训练及验证数据集的精确度 模型参数初始化#1234561.All Zero Initialization2.Initialization with Small Random Numbers3.Calibrating the Variances w = np.random.randn(n) / sqrt(n) # calibrating the variances with 1/sqrt(n)4.Current Recommendation w = np.random.randn(n) * sqrt(2.0/n) # current recommendation 超参数调试 params#可以先设置较大步数，然后找一个表现比较好的小区间，这样一步步进行，区间越来越窄，最后选出表现最好的参数 观察模型参数更新幅度(程度)#权值增量和当前权值的比值不能太大或太小，一般比值为1e-3左右比较合理太大的话考虑降低学习率；太小的话考虑增加学习率。 批处理大小 batch_size#一般取值32,64,128,256…如果数据规模&lt;1000，可以全部用于梯度下降，用批梯度的目的就是为了加快训练速度，用全梯度下降是最有效的训练方式，只是反向传播一次需要很久的时间，训练起来很慢;如果你的训练类别比较的多，建议batch_size不要选择太小，上千的类别数，batch_size应该&gt;=128，不然会震荡严重。batch_size=all, batch learningbatch_size=small, mini batch learningbatch_size=1, online learning 学习率 learning_rate#根据网络规模和loss下降速度来选择学习率一般是0.01,0.001,0.0001,0.00001…3-5层的网络，学习率&lt;1*e-5，不然下降过快导致震荡；刚开始可以任意选一个学习率，观察loss的下降速度，如果下降很快，就减小学习率；当loss收敛后，如果loss很低且准确率也高，则结束训练基本原则：网络结构复杂，学习率不能太低，防止梯度消失； 偏置与方差 bias &amp; variance# 模型好坏的极限是由数据的质量决定的，而算法的性能只能让模型无限逼近这个极限。12345678910优化bias - 网络更大 - 训练更久 - 算法更优 - 换一个网络结构优化variance - 数据更多 - Dropout - 正则化 - 换一个网络结构 查看GPU状态 gpustat#123451.nvidia-smi2.gpustat [pip install gpustat]3.实时监控3.1 watch nvidia-smi3.2 watch --color -n1 gpustat [推荐] 优化算法#性能提升#123451.从数据上提升性能2.从算法上提升性能3.从算法调优上提升性能4.从模型融合上提升性能性能提升的力度按上表的顺序从上到下依次递减 测评#参考# 深度学习性能提升的诀窍]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DL | 参数初始化]]></title>
    <url>%2F2019%2F04%2F03%2Fdl_basic%2F</url>
    <content type="text"><![CDATA[目录# 初始化为0 随机初始化 Xavier He(何恺明) 资料 深度学习模型训练的过程本质是对参数进行迭代更新，这需要每个参数有相应的初始值。对一些简单的机器学习模型，或当油画函数是凸函数时，使用0初始化或者随机初始化比较有效。对于深度学习而言，非线性函数被疯狂叠加，产生非凸函数，如何选择参数初始值便成为一个值得探讨的问题 — 其本质是初始参数的选择应使得目标函数便于被优化。 初始化为0#适合简单模型比如:线性回归,logistic回归如果所有的参数都是0，那么所有神经元的输出都将是相同的，那在back propagation的时候同一层内所有神经元的行为也是相同的 — gradient相同，weight update也相同。 随机初始化#适合层数不多的网络随着层数增加,梯度会变得很小,使得网络参数更新困难 Xavier#可以解决上随机初始化问题,但是对tanh是有效的,对于Relu依然有问题Xavier初始化的基本思想是保持输入和输出的方差一致，这样就避免了所有输出值都趋向于0。 1W = tf.Variable(np.random.randn(node_in, node_out)) / np.sqrt(node_in) He(何恺明)#在Relu中推荐使用Xavier Initialization的变种He Initialization(何恺明) 12import numpy as npW = np.random.randn(node_in, node_out) / np.sqrt(node_in / 2) 使用Batch Normalization Layer可以有效降低深度网络对weight初始化的依赖： 123import tensorflow as tf# put this before nonlinear transformationlayer = tf.contrib.layers.batch_norm(layer, center=True, scale=True,is_training=True) Batch Normalization Layer 可以削弱bad initialization的影响，其基本思想是：If you want it, just make it! 我们想要的是在非线性变换之前，输出值应该有比较好的分布（例如高斯分布），以便于反向传播计算梯度，更新参数。Batch Normalization将输出值强行做一次高斯归一化和线性变换. 资料# 网络参数初始化 聊一聊深度学习的weight initialization mml-book Deep Learning 中文版 机器学习算法优缺点对比及选择（汇总篇） TLCL linux命令大全]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx | 反向代理]]></title>
    <url>%2F2019%2F04%2F03%2Fnginx_reverseproxy%2F</url>
    <content type="text"><![CDATA[目录# 基本介绍 使用方法 功能特点 反向代理 参考 基本介绍#使用方法#功能特点#反向代理#参考# Nginx 中文文档]]></content>
      <categories>
        <category>网站服务</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐算法 | 基础知识]]></title>
    <url>%2F2019%2F03%2F31%2Frecommender_basic%2F</url>
    <content type="text"><![CDATA[目录# 介绍 相关技术 资料 参考 名词 介绍#相关技术#资料# 推荐系统工程师技能树-智能推荐系统 深度学习与推荐系统完结篇201903.31- 智能推荐系统 参考#名词#]]></content>
      <categories>
        <category>推荐算法</category>
      </categories>
      <tags>
        <tag>Recommendation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作 | 经验总结]]></title>
    <url>%2F2019%2F03%2F31%2Fjob_exp%2F</url>
    <content type="text"><![CDATA[目录# 分布式系统 微信公众号 Github 知乎 其他资料 线程 进程 协程 LRU原理和Redis实现——一个今日头条的面试题 协同过滤算法冷启动问题 长尾问题 分布式系统# 深入浅出分布式基础架构 工作黑名单公司 微信公众号# 我的2019秋招算法面经(含大疆、阿里、腾讯、头条等) 找工作的经验总结（一）-深度学习自然语言处理 2019 最新 Java 面试题汇总，附答案-搜云库技术团队 如何顺利拿到 NLP 算法工程师 Offer ？-LeetCode力扣 从写简历到面试，这是一份AI公司应聘全面指南-机器学习算法与Python学习 75道常见AI面试题，看看你的知识盲点在哪？（附解析）-机器学习算法与自然语言处理 110道python面试题-机器学习算法那些事 技术面试复习大纲-CyC2018 记一次蚂蚁金服的面试经历-纯洁的微笑 Github# 2019届秋招面经集合-github 关于python的面试题-github 互联网 Java 工程师进阶知识-github 深度学习面试题目汇总-github JavaGuide 知乎# 2019年校招，你经历了什么？-知乎 其他资料# 各大互联网公司架构演进之路汇总 公众号文章目录精心整理-机器学习算法那些事 北大课程资料 浙大课程资料 有趣的python数据分析 面试之链表问题集锦（上） 面试之链表问题集锦（下） 机器学习算法优缺点对比及选择（汇总篇） 干货 | 你是不是希望一月入门深度学习，三月中一篇顶会？– 关于做科研的态度和方法的一点感想 社招面经总结——算法题篇]]></content>
      <categories>
        <category>工作面试</category>
      </categories>
      <tags>
        <tag>Job</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CA | 入门基础和资料]]></title>
    <url>%2F2019%2F03%2F31%2Fcomputional_ad_basic%2F</url>
    <content type="text"><![CDATA[目录# 计算广告介绍 与推荐系统的区别 与传统广告的区别 与搜索广告的区别(SEA) 计算广告的分类 互联网广告的意义 计算广告的参与方 信息流广告 相关技术 资料 参考 名词 广告是用来说服受众采取某些行动的营销沟通形式，通常跟商业、政治或者意识形态有关。广告由讯息与传递讯息的媒介构成。WARC：2019年全球广告收入达到了6160亿美元,预计增长4.3%。 计算广告介绍# Find the “best match” between a given user in a given context and a suitable advertisement.计算广告学是一门正在兴起的分支学科，它涉及到大规模搜索和文本分析、信息获取、统计模型、机器学习、分类、优化以及微观经济学。计算广告学所面临的最主要挑战是在特定语境下特定用户和相应的广告之间找到“最佳匹配”。语境可以是用户在搜索引擎中输入的查询词(”Sponsored Search”)，也可以是用户正在读的网页(”Content Match”以及”Display Ads”)，还可以是用户正在看的电影等等,而与用户相关的信息可能非常多也可能非常少，潜在广告的数量可能达到几十亿。因此，取决于对“最佳匹配”的定义，面临的挑战可能导致在复杂约束条件下的大规模优化和搜索问题。 与推荐系统的区别# 推荐系统的目标往往是为了改善用户体验，而计算广告的目标则是直接提高收益从产品的角度来说，一个是用户产品，一个是商业产品从用户体验上来说，一般来说，推荐是提升用户体验的，广告是伤害用户体验的。从参与者上来说，推荐的参与者是两方：用户和媒体，广告的参与者是三方：用户、媒体、广告主。从实现难度来说，一般是广告要比推荐困难。从技术组成上来说，核心都是机器学习，这可能是最大的共同点了 与传统广告的区别# 传统广告： 相对而言平台较小－－杂志、广告牌、报纸、传单、电视等每个平台花费巨资（几百万的电视广告费用）不可能个性化只能由聪明的广告人来决定在哪里投放很难度量投资回报率(ROI) 计算广告： 亿级别的投放机会亿级别的创意形式完全个性化每次投放而言花费很小更容易度量 与搜索广告的区别(SEA)# 搜索广告是由搜索关键词驱动的广告。广告主选择一个“竞价词”，当用户触发某个搜索请求时，广告主的广告得以展现。 计算广告的分类# 根据广告主的计费方式 123千次展现付费 CPM(cost per thousand impressions) 主要用于品牌曝光,例如淘宝的钻展业务每次点击扣费 CPC(cost per click) 通常用于文本广告,例如百度凤巢，Google Adwords成交/行为付费 CPT/CPA(cost per transaction/action) 例如淘宝客业务 根据展现形式 1图片广告[Graphical Ads]、文本广告[Textual Ads]、视频等。 根据不同的产品形式 12345搜索广告(Sponsored Search)，例如百度凤巢，Google Adwords上下文广告[Contexual Ads]，例如Google Adsense展示广告[Display ads]，例如淘宝钻展业务线定向广告[Targeting Ads]，例如Google Adsense在互联网中，搜索广告是最主要的文本广告的形式 互联网广告的意义#广告支撑起了互联网上一个巨大的生态系统： 1231.内容提供商通过广告赚钱，养活了 宏观／微观的内容提供商 ［就是各种大小网站］2.精准触达／定向使得长尾生意成为可能3.广告主的收入使得大批“免费”的服务成为可能：Facebook, Google, Twitter,Yahoo 计算广告的参与方#12341.流量提供方(Publishers)2.广告主(Advertisers)3.浏览者／用户(Users)4.广告平台／广告网络(Match maker/Ad network) 各方有不同的诉求：流量提供者渴望每次展现/搜索的高收益，广告主渴望高投资回报率(ROI)和流量，用户希望高相关性，广告网络渴望收益与市场份额。而广告的选择，就是要兼顾四个参与者的收益，达到最优状态,需要权衡长期和短期的商业目标。 信息流广告# 又叫原生广告,又叫最不像广告的广告，又叫长得最像内容的广告 信息流(Feeds)广告，是在社交媒体用户好友动态、或者资讯媒体和视听媒体内容流中的广告。在2006年由Facebook 首先推出。这种穿插在内容流中的广告，对用户来说体验相对较好，对广告主来说可以利用用户的标签进行精准投放，因此特别是在移动互联网时代到来后迎来了爆炸式的增长，几乎所有的互联网媒体都推出了信息流广告平台。以前是搜索引擎广告，未来是DSP，搜索引擎广告胜在庞大的数据量，DSP胜在挖掘技术。信息流广告是将程序化购买与互动程度高的社交平台结合在一起，具有投用户所好、可分享、可评论等特点，这些特点决定了它以一种十分自然的方式融入到用户的好友动态中，有很高的触达率。 相关技术#1、用户画像（受众定向） 用户画像对媒体方来说非常重要，因为它决定了广告资源的购买者。尤其在程序化交易广告方式中，媒体方需要将用户画像和用户的情景数据一同广播出来询价，媒体对用户画像的准确性决定了DSP出价的情况。此外，DSP等厂商也会对用户进行画像以补充媒体方的用户数据。 2、在线分配 由于很多媒体除了程序化交易广告外，还有合约广告的要求，包括展示量要求等。因此，对于某个广告位在某个时间是否需要出售给DSP等需要考虑，这就出现了在线分配等要求。对于一个广告位满足多个合约的时候也需要在线分配来保证合约的完成和利益最大化。 3、流量预测 如前所述，媒体方的广告资源既要保证合约的完成也要向DSP询价进入程序化交易，因此流量预测对于完成合约非常重要，也保证了资源的不浪费。 4、点击率预测 点击率预测对于DSP来说很重要，他们预测点击率来对广告进行排序，进而预测期望收入来用于出价。通常点击率被建模成回归问题。 5、出价策略 在说出价策略之前先说一下广告中的定价的问题。广告的竞价并不是价高者得，原因在于价高者得会导致市场的总收入减少。例如甲、乙分别出价1元和2元竞价，乙赢了，那么乙会在下次调低价格直到变成了1.01，以后会保持这个水平。如果有个丙加入，经过不断尝试，发现只要出价1.02就可以拿到广告位了。而在线广告的定价策略是，如果只有甲、乙分别出价1元和2元竞价，乙赢了，但是收下一名甲的出价，即1元钱，这样乙出高价赢了竞拍，但实际出价也变少了，那乙也就没有动力调低出价了，当丙加入的时候，也必须出高于2元的价格才能拿到竞拍。这样的机制保证了更好的收益和稳定性。因此DSP的一个问题是出价策略，即在预算有限的情况下，对当前市场价格有所估计，并在全局水平上将价格集中在利润较高的广告位上。 6、询价优化 对于ADX来说，撮合交易消耗的是带宽和计算资源，如何在较低的成本下获得更高的收益。如果没有成本约束，每次询价发给所有的DSP即可，但是成本约束下需要考虑对哪部分DSP询价既可以保证所有的DSP都尽可能参与又能保证降低不必要的询价成本就是一个有意义的问题了。 资料# 计算广告学笔记之基础概念 计算广告学 讲师：刘鹏 msande239 计算广告系列 计算广告系统算法与架构综述 参考# 计算广告及搜索广告简介 互联网搜索广告介绍 信息流广告是什么意思 - 知乎 互联网广告投放有哪些入门/基础知识 微博、百度、今日头条的信息流广告都是怎么玩的？ 一文读懂微信朋友圈广告投放全流程，附案例~ 信息流广告优化，究竟是优化什么？哪些指标需要关注？ 写给普通人的CTR预估科普 互联网广告CTR预估新算法：基于神经网络的DeepFM原理解读 名词# 计算广告系统算法与架构综述 SSP（Supply-Side Platform，供应方平台）,供应方平台能够让媒体主也介入广告交易，从而使它们的库存广告可用。 DSP（Demand-Side Platform），就是需求方平台，以精准营销为核心理念。这一概念起源于网络广告发达的欧美，是伴随着互联网和广告业的飞速发展新兴起的网络广告领域。 RTB（Real Time Bidding，实时竞价）定义：是一种利用第三方技术在数以百万计的网站或移动应用上针对每一个用户展示行为进行评估以及出价的竞价技术。 Ad Exchange 广告交易平台,一个开放的、能够将媒体主和广告商联系在一起的在线广告市场(类似于股票交易所) DMP 数据管理平台 CPM（Cost Per Mille）按千次展现计费,即千人展示成本，即广告被展示1000次所需要的费用。 CPT（Cost Per Time）是一种以时间来计费的广告，很多平台都是按照“一个星期多少钱”、“一个月多少钱”这种固定收费模式来收费。 CPC（Cost Per Click）按点击计费,即单次点击成本，即广告被点击一次所需要的费用。普通竞价CPC是最常规的点击竞价方式，可以简单理解为出价越高，广告位置越靠前，获取的优质广告资源越多。需要有较高的广告投放和数据优化技巧与经验。 CPA（Cost Per Action）按成果数计费,即单次行为成本，如电话咨询，即一个客户咨询电话所需费用；表单提交，即用户提交一次个人信息所需费用；单次下载成本，即APP被下载一次所需要的费用。仅限安卓APP。 CPS（Cost Per Sales）是按实际销售产品的提成来换算广告费的广告。CPS广告同CPA广告一样，广告主为规避广告费用风险，按照广告点击之后产生的实际销售的提成付给广告站点销售提成费用。 CPE（Click per Engagement）即按参与计费，免费曝光，用户看到广告后关注、转发、收藏、点击、点赞(一个用户不管发生几次行为，都只计算1次互动)，才会计费。这种计费方式是微博特有的。 CPM和CPC是主流信息流广告平台最常见的2种计费方式，在此基础上，各个平台都在探索更有效的计费方式CVR (Click Value Rate): 转化率，衡量CPA广告效果的指标 CTR (Click Through Rate): 点击率 PV (Page View): 流量，页面浏览量 ADPV (Advertisement Page View): 载有广告的pageview流量 RPS (Revenue Per Search): 每搜索产生的收入，衡量搜索结果变现能力指标 ROI（Return on Investment）投资回报率(ROI)是指通过投资而应返回的价值，它涵盖了企业的获利目标。 KPI（Key Performance Indicator），关键绩效指标 做大,就是增加曝光,让更多的人接触到广告。这样进入漏斗(转化漏斗)的人越多，最终有效数也就越多。 做平,所谓做平其实就是提高每一个层级(转化漏斗)的转换率，让进入下一个层级的用户数尽可能多。 漏斗模型 媒体（广告位的供给方）代表媒体利益的需求方平台（SSP）聚合媒体资源的广告网络（ADN）广告主（广告位的需求方）聚合广告资源的需求方平台（DSP）广告交易平台（ADX） ADN（ad Network）， 广告网络]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>Computational Advertising</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numpy | 数据分析练习]]></title>
    <url>%2F2019%2F03%2F30%2Fnumpy_data_analysis%2F</url>
    <content type="text"><![CDATA[目录# 1、导入numpy作为np，并查看版本 2、如何创建一维数组？ 3. 如何创建一个布尔数组？ 4. 如何从一维数组中提取满足指定条件的元素？ 5. 如何用numpy数组中的另一个值替换满足条件的元素项？ 6. 如何在不影响原始数组的情况下替换满足条件的元素项？ 7. 如何改变数组的形状？ 8. 如何垂直叠加两个数组？ 9. 如何水平叠加两个数组？ 10. 如何在无硬编码的情况下生成numpy中的自定义序列？ 11. 如何获取两个numpy数组之间的公共项？ 12. 如何从一个数组中删除存在于另一个数组中的项？ 13. 如何得到两个数组元素匹配的位置？ 14. 如何从numpy数组中提取给定范围内的所有数字？ 15. 如何创建一个python函数来处理scalars并在numpy数组上工作？ 16. 如何交换二维numpy数组中的两列？ 17. 如何交换二维numpy数组中的两行？ 18. 如何反转二维数组的行？ 19. 如何反转二维数组的列？ 20. 如何创建包含5到10之间随机浮动的二维数组？ 21. 如何在numpy数组中只打印小数点后三位？ 22. 如何通过e式科学记数法（如1e10）来打印一个numpy数组？ 23. 如何限制numpy数组输出中打印的项目数？ 24. 如何打印完整的numpy数组而不截断 25. 如何导入数字和文本的数据集保持文本在numpy数组中完好无损？ 26. 如何从1维元组数组中提取特定列？ 27. 如何将1维元组数组转换为2维numpy数组？ 28. 如何计算numpy数组的均值，中位数，标准差？ 29. 如何规范化数组，使数组的值正好介于0和1之间？ 30. 如何计算Softmax得分？ 31. 如何找到numpy数组的百分位数？ 32. 如何在数组中的随机位置插入值？ 33. 如何在numpy数组中找到缺失值的位置？ 34. 如何根据两个或多个条件过滤numpy数组？ 35. 如何从numpy数组中删除包含缺失值的行？ 36. 如何找到numpy数组的两列之间的相关性？ 37. 如何查找给定数组是否具有任何空值？ 38. 如何在numpy数组中用0替换所有缺失值？ 39. 如何在numpy数组中查找唯一值的计数？ 40. 如何将数字转换为分类（文本）数组？ 41. 如何从numpy数组的现有列创建新列？ 42. 如何在numpy中进行概率抽样？ 43. 如何在按另一个数组分组时获取数组的第二大值？ 44. 如何按列对2D数组进行排序 45. 如何在numpy数组中找到最常见的值？ 46. 如何找到第一次出现的值大于给定值的位置？ 47. 如何将大于给定值的所有值替换为给定的截止值？ 48. 如何从numpy数组中获取最大n值的位置？ 49. 如何计算数组中所有可能值的行数？ 50. 如何将数组转换为平面一维数组？ 51. 如何在numpy中为数组生成单热编码？ 52. 如何创建按分类变量分组的行号？ 53. 如何根据给定的分类变量创建组ID？ 54. 如何使用numpy对数组中的项进行排名？ 55. 如何使用numpy对多维数组中的项进行排名？ 56. 如何在二维numpy数组的每一行中找到最大值？ 57. 如何计算二维numpy数组每行的最小值？ 58. 如何在numpy数组中找到重复的记录？ 59. 如何找出数字的分组均值？ 60. 如何将PIL图像转换为numpy数组？ 61. 如何删除numpy数组中所有缺少的值？ 62. 如何计算两个数组之间的欧氏距离？ 63. 如何在一维数组中找到所有的局部极大值(或峰值)？ 64. 如何从二维数组中减去一维数组，其中一维数组的每一项从各自的行中减去？ 65. 如何查找数组中项的第n次重复索引？ 66. 如何将numpy的datetime 64对象转换为datetime的datetime对象？ 67. 如何计算numpy数组的移动平均值？ 68. 如何在给定起始点、长度和步骤的情况下创建一个numpy数组序列？ 69. 如何填写不规则系列的numpy日期中的缺失日期？ 70. 如何从给定的一维数组创建步长？ 文章出处 更多 1、导入numpy作为np，并查看版本#难度等级：L1问题：将numpy导入为 np 并打印版本号。答案： 123import numpy as npprint(np.__version__)# &gt; 1.13.3 你必须将numpy导入np，才能使本练习中的其余代码正常工作。 要安装numpy，建议安装anaconda，里面已经包含了numpy。 2、如何创建一维数组？#难度等级：L1问题：创建从0到9的一维数字数组 期望输出：1# &gt; array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 答案：123arr = np.arange(10)arr# &gt; array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 3. 如何创建一个布尔数组？#难度等级：L1 问题：创建一个numpy数组元素值全为True（真）的数组 答案： 1234567np.full((3, 3), True, dtype=bool)# &gt; array([[ True, True, True],# &gt; [ True, True, True],# &gt; [ True, True, True]], dtype=bool)# Alternate method:np.ones((3,3), dtype=bool) 4. 如何从一维数组中提取满足指定条件的元素？#难度等级：L1 问题：从 arr 中提取所有的奇数 给定： 1arr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 期望的输出： 1# &gt; array([1, 3, 5, 7, 9]) 答案： 123456# Inputarr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])# Solutionarr[arr % 2 == 1]# &gt; array([1, 3, 5, 7, 9]) 5. 如何用numpy数组中的另一个值替换满足条件的元素项？#难度等级：L1 问题：将arr中的所有奇数替换为-1。 给定： 1arr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 期望的输出：1# &gt; array([ 0, -1, 2, -1, 4, -1, 6, -1, 8, -1]) 答案：123arr[arr % 2 == 1] = -1arr# &gt; array([ 0, -1, 2, -1, 4, -1, 6, -1, 8, -1]) 6. 如何在不影响原始数组的情况下替换满足条件的元素项？#难度等级：L2 问题：将arr中的所有奇数替换为-1，而不改变arr。 给定：1arr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 期望的输出： 1234out# &gt; array([ 0, -1, 2, -1, 4, -1, 6, -1, 8, -1])arr# &gt; array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 答案： 123456arr = np.arange(10)out = np.where(arr % 2 == 1, -1, arr)print(arr)out# &gt; [0 1 2 3 4 5 6 7 8 9]array([ 0, -1, 2, -1, 4, -1, 6, -1, 8, -1]) 7. 如何改变数组的形状？#难度等级：L1 问题：将一维数组转换为2行的2维数组 给定： 123np.arange(10)# &gt; array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 期望的输出： 12# &gt; array([[0, 1, 2, 3, 4],# &gt; [5, 6, 7, 8, 9]]) 答案：1234arr = np.arange(10)arr.reshape(2, -1) # Setting to -1 automatically decides the number of cols# &gt; array([[0, 1, 2, 3, 4],# &gt; [5, 6, 7, 8, 9]]) 8. 如何垂直叠加两个数组？#难度等级：L2 问题：垂直堆叠数组a和数组b 给定： 12a = np.arange(10).reshape(2,-1)b = np.repeat(1, 10).reshape(2,-1) 期望的输出： 1234# &gt; array([[0, 1, 2, 3, 4],# &gt; [5, 6, 7, 8, 9],# &gt; [1, 1, 1, 1, 1],# &gt; [1, 1, 1, 1, 1]]) 答案： 12345678910111213141516a = np.arange(10).reshape(2,-1)b = np.repeat(1, 10).reshape(2,-1)# Answers# Method 1:np.concatenate([a, b], axis=0)# Method 2:np.vstack([a, b])# Method 3:np.r_[a, b]# &gt; array([[0, 1, 2, 3, 4],# &gt; [5, 6, 7, 8, 9],# &gt; [1, 1, 1, 1, 1],# &gt; [1, 1, 1, 1, 1]]) 9. 如何水平叠加两个数组？#难度等级：L2 问题：将数组a和数组b水平堆叠。 给定： 123a = np.arange(10).reshape(2,-1)b = np.repeat(1, 10).reshape(2,-1) 期望的输出： 12# &gt; array([[0, 1, 2, 3, 4, 1, 1, 1, 1, 1],# &gt; [5, 6, 7, 8, 9, 1, 1, 1, 1, 1]]) 答案： 1234567891011121314a = np.arange(10).reshape(2,-1)b = np.repeat(1, 10).reshape(2,-1)# Answers# Method 1:np.concatenate([a, b], axis=1)# Method 2:np.hstack([a, b])# Method 3:np.c_[a, b]# &gt; array([[0, 1, 2, 3, 4, 1, 1, 1, 1, 1],# &gt; [5, 6, 7, 8, 9, 1, 1, 1, 1, 1]]) 10. 如何在无硬编码的情况下生成numpy中的自定义序列？#难度等级：L2 问题：创建以下模式而不使用硬编码。只使用numpy函数和下面的输入数组a。 给定： 1a = np.array([1,2,3])` 期望的输出： 1# &gt; array([1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]) 答案： 12np.r_[np.repeat(a, 3), np.tile(a, 3)]# &gt; array([1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]) 11. 如何获取两个numpy数组之间的公共项？#难度等级：L2 问题：获取数组a和数组b之间的公共项。 给定： 12a = np.array([1,2,3,2,3,4,3,4,5,6])b = np.array([7,2,10,2,7,4,9,4,9,8]) 期望的输出： 1array([2, 4]) 答案： 1234a = np.array([1,2,3,2,3,4,3,4,5,6])b = np.array([7,2,10,2,7,4,9,4,9,8])np.intersect1d(a,b)# &gt; array([2, 4]) 12. 如何从一个数组中删除存在于另一个数组中的项？#难度等级：L2 问题：从数组a中删除数组b中的所有项。 给定： 12a = np.array([1,2,3,4,5])b = np.array([5,6,7,8,9]) 期望的输出： 1array([1,2,3,4]) 答案： 123456a = np.array([1,2,3,4,5])b = np.array([5,6,7,8,9])# From 'a' remove all of 'b'np.setdiff1d(a,b)# &gt; array([1, 2, 3, 4]) 13. 如何得到两个数组元素匹配的位置？#难度等级：L2 问题：获取a和b元素匹配的位置。 给定： 12a = np.array([1,2,3,2,3,4,3,4,5,6])b = np.array([7,2,10,2,7,4,9,4,9,8]) 期望的输出： 1# &gt; (array([1, 3, 5, 7]),) 答案：12345a = np.array([1,2,3,2,3,4,3,4,5,6])b = np.array([7,2,10,2,7,4,9,4,9,8])np.where(a == b)# &gt; (array([1, 3, 5, 7]),) 14. 如何从numpy数组中提取给定范围内的所有数字？#难度等级：L2 问题：获取5到10之间的所有项目。 给定： 1a = np.array([2, 6, 1, 9, 10, 3, 27]) 期望的输出： 1(array([6, 9, 10]),) 答案： 12345678910111213a = np.arange(15)# Method 1index = np.where((a &gt;= 5) &amp; (a &lt;= 10))a[index]# Method 2:index = np.where(np.logical_and(a&gt;=5, a&lt;=10))a[index]# &gt; (array([6, 9, 10]),)# Method 3: (thanks loganzk!)a[(a &gt;= 5) &amp; (a &lt;= 10)] 15. 如何创建一个python函数来处理scalars并在numpy数组上工作？#难度等级：L2 问题：转换适用于两个标量的函数maxx，以处理两个数组。 给定： 123456789def maxx(x, y): """Get the maximum of two items""" if x &gt;= y: return x else: return ymaxx(1, 5)# &gt; 5 期望的输出： 1234a = np.array([5, 7, 9, 8, 6, 4, 5])b = np.array([6, 3, 4, 8, 9, 7, 1])pair_max(a, b)# &gt; array([ 6., 7., 9., 8., 9., 7., 5.]) 答案： 1234567891011121314def maxx(x, y): """Get the maximum of two items""" if x &gt;= y: return x else: return ypair_max = np.vectorize(maxx, otypes=[float])a = np.array([5, 7, 9, 8, 6, 4, 5])b = np.array([6, 3, 4, 8, 9, 7, 1])pair_max(a, b)# &gt; array([ 6., 7., 9., 8., 9., 7., 5.]) 16. 如何交换二维numpy数组中的两列？#难度等级：L2 问题：在数组arr中交换列1和2。 给定： 12arr = np.arange(9).reshape(3,3)arr 答案： 123456789# Inputarr = np.arange(9).reshape(3,3)arr# Solutionarr[:, [1,0,2]]# &gt; array([[1, 0, 2],# &gt; [4, 3, 5],# &gt; [7, 6, 8]]) 17. 如何交换二维numpy数组中的两行？#难度等级：L2 问题：交换数组arr中的第1和第2行： 给定： 12arr = np.arange(9).reshape(3,3)arr 答案： 12345678# Inputarr = np.arange(9).reshape(3,3)# Solutionarr[[1,0,2], :]# &gt; array([[3, 4, 5],# &gt; [0, 1, 2],# &gt; [6, 7, 8]]) 18. 如何反转二维数组的行？#难度等级：L2 问题：反转二维数组arr的行。 给定： 12# Inputarr = np.arange(9).reshape(3,3) 答案： 12# Inputarr = np.arange(9).reshape(3,3) 12345# Solutionarr[::-1]array([[6, 7, 8], [3, 4, 5], [0, 1, 2]]) 19. 如何反转二维数组的列？#难度等级：L2 问题：反转二维数组arr的列。 给定： 12# Inputarr = np.arange(9).reshape(3,3) 答案： 12345678# Inputarr = np.arange(9).reshape(3,3)# Solutionarr[:, ::-1]# &gt; array([[2, 1, 0],# &gt; [5, 4, 3],# &gt; [8, 7, 6]]) 20. 如何创建包含5到10之间随机浮动的二维数组？#难度等级：L2 问题：创建一个形状为5x3的二维数组，以包含5到10之间的随机十进制数。 答案： 123456789101112131415# Inputarr = np.arange(9).reshape(3,3)# Solution Method 1:rand_arr = np.random.randint(low=5, high=10, size=(5,3)) + np.random.random((5,3))# print(rand_arr)# Solution Method 2:rand_arr = np.random.uniform(5,10, size=(5,3))print(rand_arr)# &gt; [[ 8.50061025 9.10531502 6.85867783]# &gt; [ 9.76262069 9.87717411 7.13466701]# &gt; [ 7.48966403 8.33409158 6.16808631]# &gt; [ 7.75010551 9.94535696 5.27373226]# &gt; [ 8.0850361 5.56165518 7.31244004]] 21. 如何在numpy数组中只打印小数点后三位？#难度等级：L1 问题：只打印或显示numpy数组rand_arr的小数点后3位。 给定： 1rand_arr = np.random.random((5,3)) 答案：12345678910111213# Inputrand_arr = np.random.random((5,3))# Create the random arrayrand_arr = np.random.random([5,3])# Limit to 3 decimal placesnp.set_printoptions(precision=3)rand_arr[:4]# &gt; array([[ 0.443, 0.109, 0.97 ],# &gt; [ 0.388, 0.447, 0.191],# &gt; [ 0.891, 0.474, 0.212],# &gt; [ 0.609, 0.518, 0.403]]) 22. 如何通过e式科学记数法（如1e10）来打印一个numpy数组？#难度等级：L1 问题：通过e式科学记数法来打印rand_arr（如1e10） 给定： 12345678# Create the random arraynp.random.seed(100)rand_arr = np.random.random([3,3])/1e3rand_arr# &gt; array([[ 5.434049e-04, 2.783694e-04, 4.245176e-04],# &gt; [ 8.447761e-04, 4.718856e-06, 1.215691e-04],# &gt; [ 6.707491e-04, 8.258528e-04, 1.367066e-04]]) 期望的输出： 123# &gt; array([[ 0.000543, 0.000278, 0.000425],# &gt; [ 0.000845, 0.000005, 0.000122],# &gt; [ 0.000671, 0.000826, 0.000137]]) 答案： 12345678910# Reset printoptions to defaultnp.set_printoptions(suppress=False)# Create the random arraynp.random.seed(100)rand_arr = np.random.random([3,3])/1e3rand_arr# &gt; array([[ 5.434049e-04, 2.783694e-04, 4.245176e-04],# &gt; [ 8.447761e-04, 4.718856e-06, 1.215691e-04],# &gt; [ 6.707491e-04, 8.258528e-04, 1.367066e-04]]) 12345np.set_printoptions(suppress=True, precision=6) # precision is optionalrand_arr# &gt; array([[ 0.000543, 0.000278, 0.000425],# &gt; [ 0.000845, 0.000005, 0.000122],# &gt; [ 0.000671, 0.000826, 0.000137]]) 23. 如何限制numpy数组输出中打印的项目数？#难度等级：L1 问题：将numpy数组a中打印的项数限制为最多6个元素。 给定： 12a = np.arange(15)# &gt; array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]) 期望的输出： 1# &gt; array([ 0, 1, 2, ..., 12, 13, 14]) 答案： 1234np.set_printoptions(threshold=6)a = np.arange(15)a# &gt; array([ 0, 1, 2, ..., 12, 13, 14]) 24. 如何打印完整的numpy数组而不截断#难度等级：L1 问题：打印完整的numpy数组a而不截断。 给定： 1234np.set_printoptions(threshold=6)a = np.arange(15)a# &gt; array([ 0, 1, 2, ..., 12, 13, 14]) 期望的输出： 12a# &gt; array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]) 答案： 12345678# Inputnp.set_printoptions(threshold=6)a = np.arange(15)# Solutionnp.set_printoptions(threshold=np.nan)a# &gt; array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]) 25. 如何导入数字和文本的数据集保持文本在numpy数组中完好无损？#难度等级：L2 问题：导入鸢尾属植物数据集，保持文本不变。 答案： 12345678910# Solutionurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species')# Print the first 3 rowsiris[:3]# &gt; array([[b'5.1', b'3.5', b'1.4', b'0.2', b'Iris-setosa'],# &gt; [b'4.9', b'3.0', b'1.4', b'0.2', b'Iris-setosa'],# &gt; [b'4.7', b'3.2', b'1.3', b'0.2', b'Iris-setosa']], dtype=object) 26. 如何从1维元组数组中提取特定列？#难度等级：L2 问题：从前面问题中导入的一维鸢尾属植物数据集中提取文本列的物种。 给定： 12url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_1d = np.genfromtxt(url, delimiter=',', dtype=None) 答案： 123456789101112# **给定：**url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_1d = np.genfromtxt(url, delimiter=',', dtype=None)print(iris_1d.shape)# Solution:species = np.array([row[4] for row in iris_1d])species[:5]# &gt; (150,)# &gt; array([b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa',# &gt; b'Iris-setosa'],# &gt; dtype='|S18') 27. 如何将1维元组数组转换为2维numpy数组？#难度等级：L2 问题：通过省略鸢尾属植物数据集种类的文本字段，将一维鸢尾属植物数据集转换为二维数组iris_2d。 给定： 12url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_1d = np.genfromtxt(url, delimiter=',', dtype=None) 答案： 12345678910111213141516# **给定：**url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_1d = np.genfromtxt(url, delimiter=',', dtype=None)# Solution:# Method 1: Convert each row to a list and get the first 4 itemsiris_2d = np.array([row.tolist()[:4] for row in iris_1d])iris_2d[:4]# Alt Method 2: Import only the first 4 columns from source urliris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])iris_2d[:4]# &gt; array([[ 5.1, 3.5, 1.4, 0.2],# &gt; [ 4.9, 3. , 1.4, 0.2],# &gt; [ 4.7, 3.2, 1.3, 0.2],# &gt; [ 4.6, 3.1, 1.5, 0.2]]) 28. 如何计算numpy数组的均值，中位数，标准差？#难度等级：L1 问题：求出鸢尾属植物萼片长度的平均值、中位数和标准差(第1列) 给定： 12url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object') 答案： 123456789# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')sepallength = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0])# Solutionmu, med, sd = np.mean(sepallength), np.median(sepallength), np.std(sepallength)print(mu, med, sd)# &gt; 5.84333333333 5.8 0.825301291785 29. 如何规范化数组，使数组的值正好介于0和1之间？#难度等级：L2 问题：创建一种标准化形式的鸢尾属植物间隔长度，其值正好介于0和1之间，这样最小值为0，最大值为1。 给定： 12url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'sepallength = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0]) 答案： 12345678910111213141516171819202122232425# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'sepallength = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0])# SolutionSmax, Smin = sepallength.max(), sepallength.min()S = (sepallength - Smin)/(Smax - Smin)# or S = (sepallength - Smin)/sepallength.ptp() # Thanks, David Ojeda!print(S)# &gt; [ 0.222 0.167 0.111 0.083 0.194 0.306 0.083 0.194 0.028 0.167# &gt; 0.306 0.139 0.139 0. 0.417 0.389 0.306 0.222 0.389 0.222# &gt; 0.306 0.222 0.083 0.222 0.139 0.194 0.194 0.25 0.25 0.111# &gt; 0.139 0.306 0.25 0.333 0.167 0.194 0.333 0.167 0.028 0.222# &gt; 0.194 0.056 0.028 0.194 0.222 0.139 0.222 0.083 0.278 0.194# &gt; 0.75 0.583 0.722 0.333 0.611 0.389 0.556 0.167 0.639 0.25# &gt; 0.194 0.444 0.472 0.5 0.361 0.667 0.361 0.417 0.528 0.361# &gt; 0.444 0.5 0.556 0.5 0.583 0.639 0.694 0.667 0.472 0.389# &gt; 0.333 0.333 0.417 0.472 0.306 0.472 0.667 0.556 0.361 0.333# &gt; 0.333 0.5 0.417 0.194 0.361 0.389 0.389 0.528 0.222 0.389# &gt; 0.556 0.417 0.778 0.556 0.611 0.917 0.167 0.833 0.667 0.806# &gt; 0.611 0.583 0.694 0.389 0.417 0.583 0.611 0.944 0.944 0.472# &gt; 0.722 0.361 0.944 0.556 0.667 0.806 0.528 0.5 0.583 0.806# &gt; 0.861 1. 0.583 0.556 0.5 0.944 0.556 0.583 0.472 0.722# &gt; 0.667 0.722 0.417 0.694 0.667 0.667 0.556 0.611 0.528 0.444] 30. 如何计算Softmax得分？#难度等级：L3 问题：计算sepallength的softmax分数。 给定： 12url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'sepallength = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0]) 答案： 12345678910111213141516171819202122232425262728# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')sepallength = np.array([float(row[0]) for row in iris])# Solutiondef softmax(x): """Compute softmax values for each sets of scores in x. https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python""" e_x = np.exp(x - np.max(x)) return e_x / e_x.sum(axis=0)print(softmax(sepallength))# &gt; [ 0.002 0.002 0.001 0.001 0.002 0.003 0.001 0.002 0.001 0.002# &gt; 0.003 0.002 0.002 0.001 0.004 0.004 0.003 0.002 0.004 0.002# &gt; 0.003 0.002 0.001 0.002 0.002 0.002 0.002 0.002 0.002 0.001# &gt; 0.002 0.003 0.002 0.003 0.002 0.002 0.003 0.002 0.001 0.002# &gt; 0.002 0.001 0.001 0.002 0.002 0.002 0.002 0.001 0.003 0.002# &gt; 0.015 0.008 0.013 0.003 0.009 0.004 0.007 0.002 0.01 0.002# &gt; 0.002 0.005 0.005 0.006 0.004 0.011 0.004 0.004 0.007 0.004# &gt; 0.005 0.006 0.007 0.006 0.008 0.01 0.012 0.011 0.005 0.004# &gt; 0.003 0.003 0.004 0.005 0.003 0.005 0.011 0.007 0.004 0.003# &gt; 0.003 0.006 0.004 0.002 0.004 0.004 0.004 0.007 0.002 0.004# &gt; 0.007 0.004 0.016 0.007 0.009 0.027 0.002 0.02 0.011 0.018# &gt; 0.009 0.008 0.012 0.004 0.004 0.008 0.009 0.03 0.03 0.005# &gt; 0.013 0.004 0.03 0.007 0.011 0.018 0.007 0.006 0.008 0.018# &gt; 0.022 0.037 0.008 0.007 0.006 0.03 0.007 0.008 0.005 0.013# &gt; 0.011 0.013 0.004 0.012 0.011 0.011 0.007 0.009 0.007 0.005] 31. 如何找到numpy数组的百分位数？#难度等级：L1 问题：找到鸢尾属植物数据集的第5和第95百分位数 给定： 12url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'sepallength = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0]) 答案： 1234567# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'sepallength = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0])# Solutionnp.percentile(sepallength, q=[5, 95])# &gt; array([ 4.6 , 7.255]) 32. 如何在数组中的随机位置插入值？#难度等级：L2 问题：在iris_2d数据集中的20个随机位置插入np.nan值 给定： 123# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='object') 答案： 123456789101112131415161718192021222324252627# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='object')# Method 1i, j = np.where(iris_2d)# i, j contain the row numbers and column numbers of 600 elements of iris_xnp.random.seed(100)iris_2d[np.random.choice((i), 20), np.random.choice((j), 20)] = np.nan# Method 2np.random.seed(100)iris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan# Print first 10 rowsprint(iris_2d[:10])# &gt; [[b'5.1' b'3.5' b'1.4' b'0.2' b'Iris-setosa']# &gt; [b'4.9' b'3.0' b'1.4' b'0.2' b'Iris-setosa']# &gt; [b'4.7' b'3.2' b'1.3' b'0.2' b'Iris-setosa']# &gt; [b'4.6' b'3.1' b'1.5' b'0.2' b'Iris-setosa']# &gt; [b'5.0' b'3.6' b'1.4' b'0.2' b'Iris-setosa']# &gt; [b'5.4' b'3.9' b'1.7' b'0.4' b'Iris-setosa']# &gt; [b'4.6' b'3.4' b'1.4' b'0.3' b'Iris-setosa']# &gt; [b'5.0' b'3.4' b'1.5' b'0.2' b'Iris-setosa']# &gt; [b'4.4' nan b'1.4' b'0.2' b'Iris-setosa']# &gt; [b'4.9' b'3.1' b'1.5' b'0.1' b'Iris-setosa']] 33. 如何在numpy数组中找到缺失值的位置？#难度等级：L2 问题：在iris_2d的sepallength中查找缺失值的数量和位置（第1列） 给定： 1234# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float')iris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan 答案： 123456789101112# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])iris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan# Solutionprint("Number of missing values: \n", np.isnan(iris_2d[:, 0]).sum())print("Position of missing values: \n", np.where(np.isnan(iris_2d[:, 0])))# &gt; Number of missing values: # &gt; 5# &gt; Position of missing values: # &gt; (array([ 39, 88, 99, 130, 147]),) 34. 如何根据两个或多个条件过滤numpy数组？#难度等级：L3 问题：过滤具有petallength（第3列）&gt; 1.5 和 sepallength（第1列）&lt; 5.0 的iris_2d行 给定： 123# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3]) 答案： 12345678910111213# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])# Solutioncondition = (iris_2d[:, 2] &gt; 1.5) &amp; (iris_2d[:, 0] &lt; 5.0)iris_2d[condition]# &gt; array([[ 4.8, 3.4, 1.6, 0.2],# &gt; [ 4.8, 3.4, 1.9, 0.2],# &gt; [ 4.7, 3.2, 1.6, 0.2],# &gt; [ 4.8, 3.1, 1.6, 0.2],# &gt; [ 4.9, 2.4, 3.3, 1. ],# &gt; [ 4.9, 2.5, 4.5, 1.7]]) 35. 如何从numpy数组中删除包含缺失值的行？#难度等级：L3: 问题：选择没有任何nan值的iris_2d行。 给定： 123# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3]) 答案： 123456789101112131415161718# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])iris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan# Solution# No direct numpy function for this.# Method 1:any_nan_in_row = np.array([~np.any(np.isnan(row)) for row in iris_2d])iris_2d[any_nan_in_row][:5]# Method 2: (By Rong)iris_2d[np.sum(np.isnan(iris_2d), axis = 1) == 0][:5]# &gt; array([[ 4.9, 3. , 1.4, 0.2],# &gt; [ 4.7, 3.2, 1.3, 0.2],# &gt; [ 4.6, 3.1, 1.5, 0.2],# &gt; [ 5. , 3.6, 1.4, 0.2],# &gt; [ 5.4, 3.9, 1.7, 0.4]]) 36. 如何找到numpy数组的两列之间的相关性？#难度等级：L2 问题：在iris_2d中找出SepalLength（第1列）和PetalLength（第3列）之间的相关性 给定： 123# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3]) 答案： 1234567891011121314151617181920# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])# Solution 1np.corrcoef(iris[:, 0], iris[:, 2])[0, 1]# Solution 2from scipy.stats.stats import pearsonr corr, p_value = pearsonr(iris[:, 0], iris[:, 2])print(corr)# Correlation coef indicates the degree of linear relationship between two numeric variables.# It can range between -1 to +1.# The p-value roughly indicates the probability of an uncorrelated system producing # datasets that have a correlation at least as extreme as the one computed.# The lower the p-value (&lt;0.01), stronger is the significance of the relationship.# It is not an indicator of the strength.# &gt; 0.871754157305 37. 如何查找给定数组是否具有任何空值？#难度等级：L2 问题：找出iris_2d是否有任何缺失值。 给定： 123# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3]) 答案： 123456# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])np.isnan(iris_2d).any()# &gt; False 38. 如何在numpy数组中用0替换所有缺失值？#难度等级：L2 问题：在numpy数组中将所有出现的nan替换为0 给定： 1234# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])iris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan 答案： 123456789101112# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])iris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan# Solutioniris_2d[np.isnan(iris_2d)] = 0iris_2d[:4]# &gt; array([[ 5.1, 3.5, 1.4, 0. ],# &gt; [ 4.9, 3. , 1.4, 0.2],# &gt; [ 4.7, 3.2, 1.3, 0.2],# &gt; [ 4.6, 3.1, 1.5, 0.2]]) 39. 如何在numpy数组中查找唯一值的计数？#难度等级：L2 问题：找出鸢尾属植物物种中的独特值和独特值的数量 给定： 1234# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species') 答案： 12345678910111213# Import iris keeping the text column intacturl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species')# Solution# Extract the species column as an arrayspecies = np.array([row.tolist()[4] for row in iris])# Get the unique values and the countsnp.unique(species, return_counts=True)# &gt; (array([b'Iris-setosa', b'Iris-versicolor', b'Iris-virginica'],# &gt; dtype='|S15'), array([50, 50, 50])) 40. 如何将数字转换为分类（文本）数组？#难度等级：L2 问题：将iris_2d的花瓣长度（第3列）加入以形成文本数组，这样如果花瓣长度为： Less than 3 –&gt; ‘small’ 3-5 –&gt; ‘medium’ ‘&gt;=5 –&gt; ‘large’ 给定： 1234# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species') 答案： 123456789101112131415# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species')# Bin petallength petal_length_bin = np.digitize(iris[:, 2].astype('float'), [0, 3, 5, 10])# Map it to respective categorylabel_map = &#123;1: 'small', 2: 'medium', 3: 'large', 4: np.nan&#125;petal_length_cat = [label_map[x] for x in petal_length_bin]# Viewpetal_length_cat[:4]&lt;# &gt; ['small', 'small', 'small', 'small'] 41. 如何从numpy数组的现有列创建新列？#难度等级：L2 问题：在iris_2d中为卷创建一个新列，其中volume是（pi x petallength x sepal_length ^ 2）/ 3 给定： 1234# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species') 答案： 12345678910111213141516171819202122# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris_2d = np.genfromtxt(url, delimiter=',', dtype='object')# Solution# Compute volumesepallength = iris_2d[:, 0].astype('float')petallength = iris_2d[:, 2].astype('float')volume = (np.pi * petallength * (sepallength**2))/3# Introduce new dimension to match iris_2d'svolume = volume[:, np.newaxis]# Add the new columnout = np.hstack([iris_2d, volume])# Viewout[:4]# &gt; array([[b'5.1', b'3.5', b'1.4', b'0.2', b'Iris-setosa', 38.13265162927291],# &gt; [b'4.9', b'3.0', b'1.4', b'0.2', b'Iris-setosa', 35.200498485922445],# &gt; [b'4.7', b'3.2', b'1.3', b'0.2', b'Iris-setosa', 30.0723720777127],# &gt; [b'4.6', b'3.1', b'1.5', b'0.2', b'Iris-setosa', 33.238050274980004]], dtype=object) 42. 如何在numpy中进行概率抽样？#难度等级：L3 问题：随机抽鸢尾属植物的种类，使得刚毛的数量是云芝和维吉尼亚的两倍 给定： 123# Import iris keeping the text column intacturl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object') 答案： 123456789101112131415161718192021# Import iris keeping the text column intacturl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')# Solution# Get the species columnspecies = iris[:, 4]# Approach 1: Generate Probablisticallynp.random.seed(100)a = np.array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])species_out = np.random.choice(a, 150, p=[0.5, 0.25, 0.25])# Approach 2: Probablistic Sampling (preferred)np.random.seed(100)probs = np.r_[np.linspace(0, 0.500, num=50), np.linspace(0.501, .750, num=50), np.linspace(.751, 1.0, num=50)]index = np.searchsorted(probs, np.random.random(150))species_out = species[index]print(np.unique(species_out, return_counts=True))# &gt; (array([b'Iris-setosa', b'Iris-versicolor', b'Iris-virginica'], dtype=object), array([77, 37, 36])) 方法2是首选方法，因为它创建了一个索引变量，该变量可用于取样2维表格数据。 43. 如何在按另一个数组分组时获取数组的第二大值？#难度等级：L2 问题：第二长的物种setosa的价值是多少 给定： 1234# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species') 答案： 123456789101112# Import iris keeping the text column intacturl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')# Solution# Get the species and petal length columnspetal_len_setosa = iris[iris[:, 4] == b'Iris-setosa', [2]].astype('float')# Get the second last valuenp.unique(np.sort(petal_len_setosa))[-2]# &gt; 1.7 44. 如何按列对2D数组进行排序#难度等级：L2 问题：根据sepallength列对虹膜数据集进行排序。 给定： 123url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species') 答案： 12345678910111213141516171819202122# Sort by column position 0: SepalLengthprint(iris[iris[:,0].argsort()][:20])# &gt; [[b'4.3' b'3.0' b'1.1' b'0.1' b'Iris-setosa']# &gt; [b'4.4' b'3.2' b'1.3' b'0.2' b'Iris-setosa']# &gt; [b'4.4' b'3.0' b'1.3' b'0.2' b'Iris-setosa']# &gt; [b'4.4' b'2.9' b'1.4' b'0.2' b'Iris-setosa']# &gt; [b'4.5' b'2.3' b'1.3' b'0.3' b'Iris-setosa']# &gt; [b'4.6' b'3.6' b'1.0' b'0.2' b'Iris-setosa']# &gt; [b'4.6' b'3.1' b'1.5' b'0.2' b'Iris-setosa']# &gt; [b'4.6' b'3.4' b'1.4' b'0.3' b'Iris-setosa']# &gt; [b'4.6' b'3.2' b'1.4' b'0.2' b'Iris-setosa']# &gt; [b'4.7' b'3.2' b'1.3' b'0.2' b'Iris-setosa']# &gt; [b'4.7' b'3.2' b'1.6' b'0.2' b'Iris-setosa']# &gt; [b'4.8' b'3.0' b'1.4' b'0.1' b'Iris-setosa']# &gt; [b'4.8' b'3.0' b'1.4' b'0.3' b'Iris-setosa']# &gt; [b'4.8' b'3.4' b'1.9' b'0.2' b'Iris-setosa']# &gt; [b'4.8' b'3.4' b'1.6' b'0.2' b'Iris-setosa']# &gt; [b'4.8' b'3.1' b'1.6' b'0.2' b'Iris-setosa']# &gt; [b'4.9' b'2.4' b'3.3' b'1.0' b'Iris-versicolor']# &gt; [b'4.9' b'2.5' b'4.5' b'1.7' b'Iris-virginica']# &gt; [b'4.9' b'3.1' b'1.5' b'0.1' b'Iris-setosa']# &gt; [b'4.9' b'3.1' b'1.5' b'0.1' b'Iris-setosa']] 45. 如何在numpy数组中找到最常见的值？#难度等级：L1 问题：在鸢尾属植物数据集中找到最常见的花瓣长度值（第3列）。 给定： 123url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species') 答案： 12345678# **给定：**url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')# Solution:vals, counts = np.unique(iris[:, 2], return_counts=True)print(vals[np.argmax(counts)])# &gt; b'1.5' 46. 如何找到第一次出现的值大于给定值的位置？#难度等级：L2 问题：在虹膜数据集的petalwidth第4列中查找第一次出现的值大于1.0的位置。 123# **给定：**url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object') 答案： 1234567# **给定：**url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')# Solution: (edit: changed argmax to argwhere. Thanks Rong!)np.argwhere(iris[:, 3].astype(float) &gt; 1.0)[0]# &gt; 50 47. 如何将大于给定值的所有值替换为给定的截止值？#难度等级：L2 问题：从数组a中，替换所有大于30到30和小于10到10的值。 给定：12np.random.seed(100)a = np.random.uniform(1,50, 20) 答案： 123456789101112# Inputnp.set_printoptions(precision=2)np.random.seed(100)a = np.random.uniform(1,50, 20)# Solution 1: Using np.clipnp.clip(a, a_min=10, a_max=30)# Solution 2: Using np.whereprint(np.where(a &lt; 10, 10, np.where(a &gt; 30, 30, a)))# &gt; [ 27.63 14.64 21.8 30. 10. 10. 30. 30. 10. 29.18 30.# &gt; 11.25 10.08 10. 11.77 30. 30. 10. 30. 14.43] 48. 如何从numpy数组中获取最大n值的位置？#难度等级：L2 问题：获取给定数组a中前5个最大值的位置。 12np.random.seed(100)a = np.random.uniform(1,50, 20) 答案： 123456789101112131415161718192021222324# Inputnp.random.seed(100)a = np.random.uniform(1,50, 20)# Solution:print(a.argsort())# &gt; [18 7 3 10 15]# Solution 2:np.argpartition(-a, 5)[:5]# &gt; [15 10 3 7 18]# Below methods will get you the values.# Method 1:a[a.argsort()][-5:]# Method 2:np.sort(a)[-5:]# Method 3:np.partition(a, kth=-5)[-5:]# Method 4:a[np.argpartition(-a, 5)][:5] 49. 如何计算数组中所有可能值的行数？#难度等级：L4 问题：按行计算唯一值的计数。 给定： 123456789np.random.seed(100)arr = np.random.randint(1,11,size=(6, 10))arr&gt; array([[ 9, 9, 4, 8, 8, 1, 5, 3, 6, 3],&gt; [ 3, 3, 2, 1, 9, 5, 1, 10, 7, 3],&gt; [ 5, 2, 6, 4, 5, 5, 4, 8, 2, 2],&gt; [ 8, 8, 1, 3, 10, 10, 4, 3, 6, 9],&gt; [ 2, 1, 8, 7, 3, 1, 9, 3, 6, 2],&gt; [ 9, 2, 6, 5, 3, 9, 4, 6, 1, 10]]) 期望的输出： 123456&gt; [[1, 0, 2, 1, 1, 1, 0, 2, 2, 0],&gt; [2, 1, 3, 0, 1, 0, 1, 0, 1, 1],&gt; [0, 3, 0, 2, 3, 1, 0, 1, 0, 0],&gt; [1, 0, 2, 1, 0, 1, 0, 2, 1, 2],&gt; [2, 2, 2, 0, 0, 1, 1, 1, 1, 0],&gt; [1, 1, 1, 1, 1, 2, 0, 0, 2, 1]] 输出包含10列，表示从1到10的数字。这些值是各行中数字的计数。例如，cell(0，2)的值为2，这意味着数字3在第一行中恰好出现了2次。 答案： 12345678910# **给定：**np.random.seed(100)arr = np.random.randint(1,11,size=(6, 10))arr# &gt; array([[ 9, 9, 4, 8, 8, 1, 5, 3, 6, 3],# &gt; [ 3, 3, 2, 1, 9, 5, 1, 10, 7, 3],# &gt; [ 5, 2, 6, 4, 5, 5, 4, 8, 2, 2],# &gt; [ 8, 8, 1, 3, 10, 10, 4, 3, 6, 9],# &gt; [ 2, 1, 8, 7, 3, 1, 9, 3, 6, 2],# &gt; [ 9, 2, 6, 5, 3, 9, 4, 6, 1, 10]]) 12345678910111213141516171819# Solutiondef counts_of_all_values_rowwise(arr2d): # Unique values and its counts row wise num_counts_array = [np.unique(row, return_counts=True) for row in arr2d] # Counts of all values row wise return([[int(b[a==i]) if i in a else 0 for i in np.unique(arr2d)] for a, b in num_counts_array])# Printprint(np.arange(1,11))counts_of_all_values_rowwise(arr)# &gt; [ 1 2 3 4 5 6 7 8 9 10]# &gt; [[1, 0, 2, 1, 1, 1, 0, 2, 2, 0],# &gt; [2, 1, 3, 0, 1, 0, 1, 0, 1, 1],# &gt; [0, 3, 0, 2, 3, 1, 0, 1, 0, 0],# &gt; [1, 0, 2, 1, 0, 1, 0, 2, 1, 2],# &gt; [2, 2, 2, 0, 0, 1, 1, 1, 1, 0],# &gt; [1, 1, 1, 1, 1, 2, 0, 0, 2, 1]] 123456789# Example 2:arr = np.array([np.array(list('bill clinton')), np.array(list('narendramodi')), np.array(list('jjayalalitha'))])print(np.unique(arr))counts_of_all_values_rowwise(arr)# &gt; [' ' 'a' 'b' 'c' 'd' 'e' 'h' 'i' 'j' 'l' 'm' 'n' 'o' 'r' 't' 'y']# &gt; [[1, 0, 1, 1, 0, 0, 0, 2, 0, 3, 0, 2, 1, 0, 1, 0],# &gt; [0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 1, 2, 1, 2, 0, 0],# &gt; [0, 4, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 1, 1]] 50. 如何将数组转换为平面一维数组？#难度等级：L2 问题：将array_of_arrays转换为扁平线性1d数组。 给定： 12345678# **给定：**arr1 = np.arange(3)arr2 = np.arange(3,7)arr3 = np.arange(7,10)array_of_arrays = np.array([arr1, arr2, arr3])array_of_arrays# &gt; array([array([0, 1, 2]), array([3, 4, 5, 6]), array([7, 8, 9])], dtype=object) 期望的输出： 1# &gt; array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 答案： 12345678910111213141516 # **给定：**arr1 = np.arange(3)arr2 = np.arange(3,7)arr3 = np.arange(7,10)array_of_arrays = np.array([arr1, arr2, arr3])print('array_of_arrays: ', array_of_arrays)# Solution 1arr_2d = np.array([a for arr in array_of_arrays for a in arr])# Solution 2:arr_2d = np.concatenate(array_of_arrays)print(arr_2d)# &gt; array_of_arrays: [array([0, 1, 2]) array([3, 4, 5, 6]) array([7, 8, 9])]# &gt; [0 1 2 3 4 5 6 7 8 9] 51. 如何在numpy中为数组生成单热编码？#难度等级：L4 问题：计算一次性编码(数组中每个唯一值的虚拟二进制变量) 给定： 1234np.random.seed(101) arr = np.random.randint(1,4, size=6)arr# &gt; array([2, 3, 2, 2, 2, 1]) 期望输出： 123456# &gt; array([[ 0., 1., 0.],# &gt; [ 0., 0., 1.],# &gt; [ 0., 1., 0.],# &gt; [ 0., 1., 0.],# &gt; [ 0., 1., 0.],# &gt; [ 1., 0., 0.]]) 答案： 123456789101112131415161718192021222324# **给定：**np.random.seed(101) arr = np.random.randint(1,4, size=6)arr# &gt; array([2, 3, 2, 2, 2, 1])# Solution:def one_hot_encodings(arr): uniqs = np.unique(arr) out = np.zeros((arr.shape[0], uniqs.shape[0])) for i, k in enumerate(arr): out[i, k-1] = 1 return outone_hot_encodings(arr)# &gt; array([[ 0., 1., 0.],# &gt; [ 0., 0., 1.],# &gt; [ 0., 1., 0.],# &gt; [ 0., 1., 0.],# &gt; [ 0., 1., 0.],# &gt; [ 1., 0., 0.]])# Method 2:(arr[:, None] == np.unique(arr)).view(np.int8) 52. 如何创建按分类变量分组的行号？#难度等级：L3 问题：创建按分类变量分组的行号。使用以下来自鸢尾属植物物种的样本作为输入。 给定： 1234567891011url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'species = np.genfromtxt(url, delimiter=',', dtype='str', usecols=4)species_small = np.sort(np.random.choice(species, size=20))species_small# &gt; array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',# &gt; 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',# &gt; 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',# &gt; 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica',# &gt; 'Iris-virginica', 'Iris-virginica', 'Iris-virginica',# &gt; 'Iris-virginica', 'Iris-virginica', 'Iris-virginica'],# &gt; dtype='&lt;U15') 期望的输出： 1# &gt; [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 7] 答案： 1234567891011121314# **给定：**url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'species = np.genfromtxt(url, delimiter=',', dtype='str', usecols=4)np.random.seed(100)species_small = np.sort(np.random.choice(species, size=20))species_small# &gt; array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',# &gt; 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',# &gt; 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',# &gt; 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',# &gt; 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica',# &gt; 'Iris-virginica', 'Iris-virginica', 'Iris-virginica',# &gt; 'Iris-virginica'],# &gt; dtype='&lt;U15') 1print([i for val in np.unique(species_small) for i, grp in enumerate(species_small[species_small==val])]) 1[0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5] 53. 如何根据给定的分类变量创建组ID？#难度等级：L4 问题：根据给定的分类变量创建组ID。使用以下来自鸢尾属植物物种的样本作为输入。 给定： 1234567891011url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'species = np.genfromtxt(url, delimiter=',', dtype='str', usecols=4)species_small = np.sort(np.random.choice(species, size=20))species_small# &gt; array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',# &gt; 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',# &gt; 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',# &gt; 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica',# &gt; 'Iris-virginica', 'Iris-virginica', 'Iris-virginica',# &gt; 'Iris-virginica', 'Iris-virginica', 'Iris-virginica'],# &gt; dtype='&lt;U15') 期望的输出： 1# &gt; [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2] 答案： 1234567891011121314# **给定：**url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'species = np.genfromtxt(url, delimiter=',', dtype='str', usecols=4)np.random.seed(100)species_small = np.sort(np.random.choice(species, size=20))species_small# &gt; array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',# &gt; 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',# &gt; 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',# &gt; 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',# &gt; 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica',# &gt; 'Iris-virginica', 'Iris-virginica', 'Iris-virginica',# &gt; 'Iris-virginica'],# &gt; dtype='&lt;U15') 1234567891011121314# Solution:output = [np.argwhere(np.unique(species_small) == s).tolist()[0][0] for val in np.unique(species_small) for s in species_small[species_small==val]]# Solution: For Loop versionoutput = []uniqs = np.unique(species_small)for val in uniqs: # uniq values in group for s in species_small[species_small==val]: # each element in group groupid = np.argwhere(uniqs == s).tolist()[0][0] # groupid output.append(groupid)print(output)# &gt; [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2] 54. 如何使用numpy对数组中的项进行排名？#难度等级：L2 问题：为给定的数字数组a创建排名。 给定： 1234np.random.seed(10)a = np.random.randint(20, size=10)print(a)# &gt; [ 9 4 15 0 17 16 17 8 9 0] 期望输出： 1[4 2 6 0 8 7 9 3 5 1] 答案： 12345678910np.random.seed(10)a = np.random.randint(20, size=10)print('Array: ', a)# Solutionprint(a.argsort().argsort())print('Array: ', a)# &gt; Array: [ 9 4 15 0 17 16 17 8 9 0]# &gt; [4 2 6 0 8 7 9 3 5 1]# &gt; Array: [ 9 4 15 0 17 16 17 8 9 0] 55. 如何使用numpy对多维数组中的项进行排名？#难度等级：L3 问题：创建与给定数字数组a相同形状的排名数组。 给定： 12345np.random.seed(10)a = np.random.randint(20, size=[2,5])print(a)# &gt; [[ 9 4 15 0 17]# &gt; [16 17 8 9 0]] 期望输出： 12# &gt; [[4 2 6 0 8]# &gt; [7 9 3 5 1]] 答案： 1234567891011# **给定：**np.random.seed(10)a = np.random.randint(20, size=[2,5])print(a)# Solutionprint(a.ravel().argsort().argsort().reshape(a.shape))# &gt; [[ 9 4 15 0 17]# &gt; [16 17 8 9 0]]# &gt; [[4 2 6 0 8]# &gt; [7 9 3 5 1]] 56. 如何在二维numpy数组的每一行中找到最大值？#难度等级：L2 问题：计算给定数组中每行的最大值。 给定： 12345678np.random.seed(100)a = np.random.randint(1,10, [5,3])a# &gt; array([[9, 9, 4],# &gt; [8, 8, 1],# &gt; [5, 3, 6],# &gt; [3, 3, 3],# &gt; [2, 1, 9]]) 答案： 1234567891011# Inputnp.random.seed(100)a = np.random.randint(1,10, [5,3])a# Solution 1np.amax(a, axis=1)# Solution 2np.apply_along_axis(np.max, arr=a, axis=1)# &gt; array([9, 8, 6, 3, 9]) 57. 如何计算二维numpy数组每行的最小值？#难度等级：L3 问题：为给定的二维numpy数组计算每行的最小值。 给定： 12345678np.random.seed(100)a = np.random.randint(1,10, [5,3])a# &gt; array([[9, 9, 4],# &gt; [8, 8, 1],# &gt; [5, 3, 6],# &gt; [3, 3, 3],# &gt; [2, 1, 9]]) 答案： 12345678# Inputnp.random.seed(100)a = np.random.randint(1,10, [5,3])a# Solutionnp.apply_along_axis(lambda x: np.min(x)/np.max(x), arr=a, axis=1)# &gt; array([ 0.44444444, 0.125 , 0.5 , 1. , 0.11111111]) 58. 如何在numpy数组中找到重复的记录？#难度等级：L3 问题：在给定的numpy数组中找到重复的条目(第二次出现以后)，并将它们标记为True。第一次出现应该是False的。 给定： 12345# Inputnp.random.seed(100)a = np.random.randint(0, 5, 10)print('Array: ', a)# &gt; Array: [0 0 3 0 2 4 2 2 2 2] 期望的输出： 1# &gt; [False True False True False False True True True True] 答案： 123456789101112131415161718# Inputnp.random.seed(100)a = np.random.randint(0, 5, 10)## Solution# There is no direct function to do this as of 1.13.3# Create an all True arrayout = np.full(a.shape[0], True)# Find the index positions of unique elementsunique_positions = np.unique(a, return_index=True)[1]# Mark those positions as Falseout[unique_positions] = Falseprint(out)# &gt; [False True False True False False True True True True] 59. 如何找出数字的分组均值？#难度等级：L3 问题：在二维数字数组中查找按分类列分组的数值列的平均值 给定： 123url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species') 理想的输出： 123# &gt; [[b'Iris-setosa', 3.418],# &gt; [b'Iris-versicolor', 2.770],# &gt; [b'Iris-virginica', 2.974]] 答案： 1234567891011121314151617181920212223# Inputurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'iris = np.genfromtxt(url, delimiter=',', dtype='object')names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species')# Solution# No direct way to implement this. Just a version of a workaround.numeric_column = iris[:, 1].astype('float') # sepalwidthgrouping_column = iris[:, 4] # species# List comprehension version[[group_val, numeric_column[grouping_column==group_val].mean()] for group_val in np.unique(grouping_column)]# For Loop versionoutput = []for group_val in np.unique(grouping_column): output.append([group_val, numeric_column[grouping_column==group_val].mean()])output# &gt; [[b'Iris-setosa', 3.418],# &gt; [b'Iris-versicolor', 2.770],# &gt; [b'Iris-virginica', 2.974]] 60. 如何将PIL图像转换为numpy数组？#难度等级：L3 问题：从以下URL导入图像并将其转换为numpy数组。 1URL = 'https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg' 答案： 1234567891011121314151617181920from io import BytesIOfrom PIL import Imageimport PIL, requests# Import image from URLURL = 'https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg'response = requests.get(URL)# Read it as ImageI = Image.open(BytesIO(response.content))# Optionally resizeI = I.resize([150,150])# Convert to numpy arrayarr = np.asarray(I)# Optionaly Convert it back to an image and showim = PIL.Image.fromarray(np.uint8(arr))Image.Image.show(im) 61. 如何删除numpy数组中所有缺少的值？#难度等级：L2 问题：从一维numpy数组中删除所有NaN值 给定： 1np.array([1,2,3,np.nan,5,6,7,np.nan]) 期望的输出： 1array([ 1., 2., 3., 5., 6., 7.]) 答案： 123a = np.array([1,2,3,np.nan,5,6,7,np.nan])a[~np.isnan(a)]# &gt; array([ 1., 2., 3., 5., 6., 7.]) 62. 如何计算两个数组之间的欧氏距离？#难度等级：L3 问题：计算两个数组a和数组b之间的欧氏距离。 给定：12a = np.array([1,2,3,4,5])b = np.array([4,5,6,7,8]) 答案： 12345678# Inputa = np.array([1,2,3,4,5])b = np.array([4,5,6,7,8])# Solutiondist = np.linalg.norm(a-b)dist# &gt; 6.7082039324993694 63. 如何在一维数组中找到所有的局部极大值(或峰值)？#难度等级：L4 问题：找到一个一维数字数组a中的所有峰值。峰顶是两边被较小数值包围的点。 给定：1a = np.array([1, 3, 7, 1, 2, 6, 0, 1]) 期望的输出： 1# &gt; array([2, 5]) 其中，2和5是峰值7和6的位置。 答案： 12345a = np.array([1, 3, 7, 1, 2, 6, 0, 1])doublediff = np.diff(np.sign(np.diff(a)))peak_locations = np.where(doublediff == -2)[0] + 1peak_locations# &gt; array([2, 5]) 64. 如何从二维数组中减去一维数组，其中一维数组的每一项从各自的行中减去？#难度等级：L2 问题：从2d数组a_2d中减去一维数组b_1D，使得b_1D的每一项从a_2d的相应行中减去。 12a_2d = np.array([[3,3,3],[4,4,4],[5,5,5]])b_1d = np.array([1,1,1] 期望的输出： 123# &gt; [[2 2 2]# &gt; [2 2 2]# &gt; [2 2 2]] 答案： 123456789# Inputa_2d = np.array([[3,3,3],[4,4,4],[5,5,5]])b_1d = np.array([1,2,3])# Solutionprint(a_2d - b_1d[:,None])# &gt; [[2 2 2]# &gt; [2 2 2]# &gt; [2 2 2]] 65. 如何查找数组中项的第n次重复索引？#难度等级：L2 问题：找出x中数字1的第5次重复的索引。 1x = np.array([1, 2, 1, 1, 3, 4, 3, 1, 1, 2, 1, 1, 2]) 答案： 123456789x = np.array([1, 2, 1, 1, 3, 4, 3, 1, 1, 2, 1, 1, 2])n = 5# Solution 1: List comprehension[i for i, v in enumerate(x) if v == 1][n-1]# Solution 2: Numpy versionnp.where(x == 1)[0][n-1]# &gt; 8 66. 如何将numpy的datetime 64对象转换为datetime的datetime对象？#难度等级：L2 问题：将numpy的datetime64对象转换为datetime的datetime对象 12# **给定：** a numpy datetime64 objectdt64 = np.datetime64('2018-02-25 22:10:10') 答案： 1234567891011# **给定：** a numpy datetime64 objectdt64 = np.datetime64('2018-02-25 22:10:10')# Solutionfrom datetime import datetimedt64.tolist()# ordt64.astype(datetime)# &gt; datetime.datetime(2018, 2, 25, 22, 10, 10) 67. 如何计算numpy数组的移动平均值？#难度等级：L3 问题：对于给定的一维数组，计算窗口大小为3的移动平均值。 给定： 12np.random.seed(100)Z = np.random.randint(10, size=10) 答案： 1234567891011121314151617181920# Solution# Source: https://stackoverflow.com/questions/14313510/how-to-calculate-moving-average-using-numpydef moving_average(a, n=3) : ret = np.cumsum(a, dtype=float) ret[n:] = ret[n:] - ret[:-n] return ret[n - 1:] / nnp.random.seed(100)Z = np.random.randint(10, size=10)print('array: ', Z)# Method 1moving_average(Z, n=3).round(2)# Method 2: # Thanks AlanLRH!# np.ones(3)/3 gives equal weights. Use np.ones(4)/4 for window size 4.np.convolve(Z, np.ones(3)/3, mode='valid') . # &gt; array: [8 8 3 7 7 0 4 2 5 2]# &gt; moving average: [ 6.33 6. 5.67 4.67 3.67 2. 3.67 3. ] 68. 如何在给定起始点、长度和步骤的情况下创建一个numpy数组序列？#难度等级：L2 问题：创建长度为10的numpy数组，从5开始，在连续的数字之间的步长为3。 答案： 12345678910length = 10start = 5step = 3def seq(start, length, step): end = start + (step*length) return np.arange(start, end, step)seq(start, length, step)# &gt; array([ 5, 8, 11, 14, 17, 20, 23, 26, 29, 32]) 69. 如何填写不规则系列的numpy日期中的缺失日期？#难度等级：L3 问题：给定一系列不连续的日期序列。填写缺失的日期，使其成为连续的日期序列。 给定： 123456# Inputdates = np.arange(np.datetime64('2018-02-01'), np.datetime64('2018-02-25'), 2)print(dates)# &gt; ['2018-02-01' '2018-02-03' '2018-02-05' '2018-02-07' '2018-02-09'# &gt; '2018-02-11' '2018-02-13' '2018-02-15' '2018-02-17' '2018-02-19'# &gt; '2018-02-21' '2018-02-23'] 答案： 12345678910111213141516171819202122232425262728293031# Inputdates = np.arange(np.datetime64('2018-02-01'), np.datetime64('2018-02-25'), 2)print(dates)# Solution ---------------filled_in = np.array([np.arange(date, (date+d)) for date, d in zip(dates, np.diff(dates))]).reshape(-1)# add the last dayoutput = np.hstack([filled_in, dates[-1]])output# For loop version -------out = []for date, d in zip(dates, np.diff(dates)): out.append(np.arange(date, (date+d)))filled_in = np.array(out).reshape(-1)# add the last dayoutput = np.hstack([filled_in, dates[-1]])output# &gt; ['2018-02-01' '2018-02-03' '2018-02-05' '2018-02-07' '2018-02-09'# &gt; '2018-02-11' '2018-02-13' '2018-02-15' '2018-02-17' '2018-02-19'# &gt; '2018-02-21' '2018-02-23']# &gt; array(['2018-02-01', '2018-02-02', '2018-02-03', '2018-02-04',# &gt; '2018-02-05', '2018-02-06', '2018-02-07', '2018-02-08',# &gt; '2018-02-09', '2018-02-10', '2018-02-11', '2018-02-12',# &gt; '2018-02-13', '2018-02-14', '2018-02-15', '2018-02-16',# &gt; '2018-02-17', '2018-02-18', '2018-02-19', '2018-02-20',# &gt; '2018-02-21', '2018-02-22', '2018-02-23'], dtype='datetime64[D]') 70. 如何从给定的一维数组创建步长？#难度等级：L4 问题：从给定的一维数组arr中，利用步进生成一个二维矩阵，窗口长度为4，步距为2，类似于 [[0,1,2,3], [2,3,4,5], [4,5,6,7]..] 给定： 123arr = np.arange(15) arr# &gt; array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]) 期望的输出： 123456# &gt; [[ 0 1 2 3]# &gt; [ 2 3 4 5]# &gt; [ 4 5 6 7]# &gt; [ 6 7 8 9]# &gt; [ 8 9 10 11]# &gt; [10 11 12 13]] 答案： 123456789101112def gen_strides(a, stride_len=5, window_len=5): n_strides = ((a.size-window_len)//stride_len) + 1 # return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]]) return np.array([a[s:(s+window_len)] for s in np.arange(0, n_strides*stride_len, stride_len)])print(gen_strides(np.arange(15), stride_len=2, window_len=4))# &gt; [[ 0 1 2 3]# &gt; [ 2 3 4 5]# &gt; [ 4 5 6 7]# &gt; [ 6 7 8 9]# &gt; [ 8 9 10 11]# &gt; [10 11 12 13]] 文章出处#原作者为 machinelearningplus.com，翻译至：https://www.machinelearningplus.com/python/101-numpy-exercises-python/ 更多# Pandas 一文总结]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numpy | 基本用法]]></title>
    <url>%2F2019%2F03%2F30%2Fpython_numpy%2F</url>
    <content type="text"><![CDATA[目录# basic numpy ndarray and indexing 资料 123# 小技巧，实现多行输出from IPython.core.interactiveshell import InteractiveShell InteractiveShell.ast_node_interactivity = 'all' #默认为'last' basic numpy#1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# 创建向量vector = np.array([1, 2, 3, 4, 5, 6])# 创建矩阵matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# 转置向量vector.T# 转置矩阵matrix.T# 将矩阵变形为 2x6 矩阵matrix.reshape(2, 6)# 计算矩阵的逆np.linalg.inv(matrix)# 返回对角线元素matrix.diagonal()# 创建矩阵的迹 计算矩阵的迹matrix.diagonal().sum()# 展开矩阵matrix.flatten()# 返回矩阵的秩np.linalg.matrix_rank(matrix)# 返回最大元素最小元素np.min(matrix)np.max(matrix)#每列的最大元素np.max(matrix, axis=0)#列反向每行的最大元素np.max(matrix, axis=1)#行反向# 查看行和列数matrix.shape# 查看元素数(行乘列)matrix.size# 查看维数matrix.ndim# 创建稀疏矩阵from scipy import sparse# 创建矩阵matrix = np.array([[0, 0], [0, 1], [3, 0]])# 创建压缩稀疏行(CSR)矩阵matrix_sparse = sparse.csr_matrix(matrix)#将字典转换为矩阵DictVectorizer# 加载库from sklearn.feature_extraction import DictVectorizer# 我们的数据字典data_dict = [&#123;'Red':2,'Blue': 4&#125;, &#123;'Red':4,'Blue': 3&#125;, &#123;'Red':1,'Yellow': 2&#125;, &#123;'Red':2,'Yellow': 2&#125;]# 创建 DictVectorizer 对象dictvectorizer = DictVectorizer(sparse=False)# 将字典转换为特征矩阵features = dictvectorizer.fit_transform(data_dict)# 查看特征矩阵features# 查看特征矩阵的列名dictvectorizer.get_feature_names()# ['Blue', 'Red', 'Yellow']# 返回矩阵的行列式np.linalg.det(matrix)# 返回均值np.mean(matrix)# 返回方差np.var(matrix)# 返回标准差np.std(matrix)# 创建两个向量vector_a = np.array([1,2,3])vector_b = np.array([4,5,6])# 计算点积np.dot(vector_a, vector_b)# 计算点积vector_a @ vector_b ndarray and indexing#123456789# 1D Arraya = np.array([0, 1, 2, 3, 4])b = np.array((0, 1, 2, 3, 4))c = np.arange(5)#arange([start,] stop[, step,], dtype=None)d = np.linspace(0, 2*np.pi, 5)#np.linspace(start, stop, num=50...)abcd 1234567891011121314# # MD Arraya = np.array([[11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25], [26, 27, 28 ,29, 30], [31, 32, 33, 34, 35]])b = np.arange(25).reshape((-1,5))aba[2,2]b[0,0]c = a - 10 # broadcasting a-np.array([10]*25).reshape(a.shape)c 1234567# MD slicingprint(a[0, 1:4]) # &gt;&gt;&gt;[12 13 14]print(a[1:4, 0]) # &gt;&gt;&gt;[16 21 26]print(a[::2,::2]) # &gt;&gt;&gt;[[11 13 15] # [21 23 25] # [31 33 35]]print(a[:, 1]) # &gt;&gt;&gt;[12 17 22 27 32] 1234567891011121314# Array propertiesa = np.array([[11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25], [26, 27, 28 ,29, 30], [31, 32, 33, 34, 35]])print(type(a)) # &gt;&gt;&gt;&lt;class 'numpy.ndarray'&gt;print(a.dtype) # &gt;&gt;&gt;int64print(a.size) # &gt;&gt;&gt;25print(a.shape) # &gt;&gt;&gt;(5, 5)print(a.itemsize) # &gt;&gt;&gt;8print(a.ndim) # &gt;&gt;&gt;2print(a.nbytes) # &gt;&gt;&gt;200 1234567891011121314151617181920# Basic Operatorsa = np.arange(25)a = a.reshape((5, 5))b = np.array([10, 62, 1, 14, 2, 56, 79, 2, 1, 45, 4, 92, 5, 55, 63, 43, 35, 6, 53, 24, 56, 3, 56, 44, 78])b = b.reshape((5,5))print(a + b)print(a - b)print(a * b)print(a / b)print(a ** 2)print(a &lt; b) print(a &gt; b)print(a.dot(b)) # 除了 dot() 之外，这些操作符都是对数组进行逐元素运算。np.dot([1,2],[2,3]) # 1*2+2*3np.dot(a[0,:],b[:,0]) 1234567# dot, sum, min, max, cumsuma = np.arange(10)aprint(a.sum()) # &gt;&gt;&gt;45print(a.min()) # &gt;&gt;&gt;0print(a.max()) # &gt;&gt;&gt;9print(a.cumsum()) # &gt;&gt;&gt;[ 0 1 3 6 10 15 21 28 36 45] 1234567# Fancy indexing 花式索引a = np.arange(0, 100, 10)indices = [1, 5, -1]print(indices)b = a[indices]print(a) # &gt;&gt;&gt;[ 0 10 20 30 40 50 60 70 80 90]print(b) # &gt;&gt;&gt;[10 50 90] 123456789101112131415# Boolean maskingimport matplotlib.pyplot as plt%matplotlib inlinea = np.linspace(0, 2 * np.pi, 50)b = np.sin(a)plt.plot(a,b)mask = b &gt;= 0maskplt.plot(a[mask], b[mask], 'bo')mask = (b &gt;= 0) &amp; (a &lt;= np.pi / 2)masknp.pi / 2plt.plot(a[mask], b[mask], 'go')plt.show() 1234567# Incomplete Indexinga = np.arange(0, 100, 10)ab = a[:5]c = a[a &gt;= 50]print(b) # &gt;&gt;&gt;[ 0 10 20 30 40]print(c) # &gt;&gt;&gt;[50 60 70 80 90] 12345678# Wherea = np.arange(0, 100, 10)b = np.where(a &lt; 50) c = np.where(a &gt;= 50)[0]aa[b]a[c]c 12345678def qsort(arr): if len(arr)&lt;1: return arr pivot=arr[len(arr)//2] left=[x for x in arr if x &lt; pivot] right=[x for x in arr if x &gt; pivot] middle=[x for x in arr if x == pivot] return qsort(left)+middle+qsort(right) 1qsort(np.random.randint(1,20,10)) 12345678def qsort_np(arr): if arr.shape[0]&lt;1: return arr pivot=arr[arr.shape[0]//2] left=arr[arr&lt;pivot] right=arr[arr&gt;pivot] middle=arr[arr==pivot] return np.hstack((left,middle,right)) 1qsort_np((np.random.randint(1,20,10))) 123x = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])v = np.array([1, 0, 1])y = np.empty_like(x) # Create an empty matrix with the same shape as x 1234567# solve求解线性方程组 Ax=bA = np.array([[2,1,-2],[3,0,1],[1,1,-1]])b = np.transpose(np.array([[-3,5,-2]]))x = np.linalg.solve(A,b)Abx 1234567891011121314151617181920212223242526272829303132333435363738import csvimport numpy as npdef load(): X = [] y = [] with open('Housing.csv') as f: rdr = csv.reader(f) # Skip the header row next(rdr) # Read X and y for line in rdr: xline = [1.0] #bias for s in line[:-1]: xline.append(float(s)) X.append(xline) y.append(float(line[-1])) return (X,y)X0,y0=load()X0,y0=np.array(X0),np.array(y0)X0.shapey0.shaped = len(X0)-10X = np.array(X0[:d])y = np.transpose(np.array([y0[:d]]))# Compute betaXt = np.transpose(X)XtX = np.dot(Xt,X)Xty = np.dot(Xt,y)beta = np.linalg.solve(XtX,Xty)print(beta)# Make predictions for the last 10 rows in the data setfor data,actual in zip(X0[d:],y0[d:]): x = np.array([data]) prediction = np.dot(x,beta) print('prediction = '+str(prediction[0,0])+' actual = '+str(actual)) 资料# learn-python cs231 python cs228 python scipy numpy 100 numpy practice]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrome | 好用的插件]]></title>
    <url>%2F2019%2F03%2F30%2Fchrome_plugins%2F</url>
    <content type="text"><![CDATA[目录# Easy to RSS cVim IDM Integration Module Infinity OneTab Octotree XPath Helper Open in Colab Sourcegraph 相关链接 Easy to RSS# Retreive RSS feeds URLs from WebSite, RSSHub supported cVim# An extension adding Vim-like bindings to Google Chrome IDM Integration Module# Download files with Internet Download Manager Infinity# 百万用户选择的新标签页和快速拨号，自由添加网站图标，云端高清壁纸，快速访问书签、天气、笔记、待办事项、扩展管理与历史记录 OneTab# 节省高达95％的内存，并减轻标签页混乱现象 Octotree# Code tree for GitHub XPath Helper# Extract, edit, and evaluate XPath queries with ease. Open in Colab# Open a Github-hosted notebook in Google Colab Sourcegraph# Code intelligence for your code host and code reviews: hovers, documentation, definitions, and references in files, PRs, and diffs 相关链接# extfans]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python | 好用的包]]></title>
    <url>%2F2019%2F03%2F30%2Fpython_pkg%2F</url>
    <content type="text"><![CDATA[目录# nltk pattern TextBlob pypdf | pywin32 feedparser pydash Matplotlib Seaborn Plotly PyCharts Dash graphviz NN-SVG knockknock networkx texttable python-goose tqdm loguru ds-cheatsheets scrapydweb 相关连接 nltk# 自然语言处理工具 NLTK 在使用 Python 处理自然语言的工具中处于领先的地位。它提供了 WordNet 这种方便处理词汇资源的接口，以及分类、分词、词干提取、标注、语法分析、语义推理等类库。 pattern# Pattern是基于web的Python挖掘模块，包含如下工具： 数据挖掘：Web服口(Google,Twitter,Wikipedia),网络爬虫,HTML DOM 解析。 自然语言处理：POS标注,n-gram搜索,情感分析,词云。 机器学习：向量空间模VSM),聚类,分类(KNN,SVM,Perceptron)。 网络分析：图中心和可视 TextBlob# docement TextBlob 是基于NLTK和pattern的工具, 有两者的特性。如下：名词短语提前POS标注情感分析分类 (Naive Bayes, Decision Tree)谷歌翻译分词和分句词频和短语频率统计句法解析n-grams模型词型转换和词干提取拼写校正通过词云整合添加新的语言和模型 pypdf | pywin32# 处理pdf和word等二进制文件 feedparser# 处理RSS,CDN,Atom等内容解析 pydash# pydash pydash是一个基于python和django的性能监测工具。可以运行在centos、ubuntu等主流的linux发行版本上，能够统计服务器资源，监控服务器性能 参考 Matplotlib# Matplotlib Seaborn# Seaborn Plotly# Plotly PyCharts# Pycharts Dash# Dash 一款只用几百行 Python 代码就可以轻易实现数据分析可视化的利器，是目前 Python 社区数据可视化主要的工具之一。具有：使用简单、易于扩展、开发团队活跃等特点 graphviz# graphviz Graphviz is open source graph visualization software. Graph visualization is a way of representing structural information as diagrams of abstract graphs and networks. It has important applications in networking, bioinformatics, software engineering, database and web design, machine learning, and in visual interfaces for other technical domains. NN-SVG# NN-SVG Demo NN-SVG is a tool for creating Neural Network (NN) architecture drawings parametrically rather than manually. It also provides the ability to export those drawings to Scalable Vector Graphics (SVG) files, suitable for inclusion in academic papers or web pages. knockknock# knockknock 当你的模型训练完成或者训练过程出现问题时，它会及时通知你。而你只需要写两行代码。 微信文章12该库可无缝使用，只需对代码做最小的修改：你只需在主函数调用上加一个装饰器。现在有两种设置通知的方式：邮件和 Slack。 networkx# networkx NetworkX是一个用Python语言开发的图论与复杂网络建模工具，内置了常用的图与复杂网络分析算法，可以方便的进行复杂网络数据分析、仿真建模等工作。networkx支持创建简单无向图、有向图和多重图（multigraph）；内置许多标准的图论算法，节点可为任意数据；支持任意的边值维度，功能丰富，简单易用。 texttable# texttable Python module for creating simple ASCII tables python-goose# python-goose Goose 用于文章提取器，提取中文内容1234567&gt;&gt;&gt; from goose import Goose&gt;&gt;&gt; from goose.text import StopWordsChinese&gt;&gt;&gt; url = 'http://www.bbc.co.uk/zhongwen/simp/chinese_news/2012/12/121210_hongkong_politics.shtml'&gt;&gt;&gt; g = Goose(&#123;'stopwords_class': StopWordsChinese&#125;)&gt;&gt;&gt; article = g.extract(url=url)&gt;&gt;&gt; print article.cleaned_text[:150]香港行政长官梁振英在各方压力下就其大宅的违章建筑（僭建）问题到立法会接受质询，并向香港民众道歉。 tqdm# tqdm 强大、快速、易扩展的 Python 进度条库12345from tqdm import tqdmfor i in tqdm(range(10000)): pass# 输出结果：# 76%|████████████████████████████ | 7568/10000 [00:33&lt;00:10, 229.00it/s] loguru# loguru 一个让Python日志变得简单的库1234567import loguru&gt;&gt;&gt;loguru.logger.info('test')2019-03-30 13:28:48.327 | INFO | __main__:&lt;module&gt;:1 - test&gt;&gt;&gt;loguru.logger.debug('test')2019-03-30 13:28:48.327 | DEBUG | __main__:&lt;module&gt;:1 - test&gt;&gt;&gt;loguru.logger.error('test')2019-03-30 13:28:48.327 | ERROR | __main__:&lt;module&gt;:1 - test ds-cheatsheets# ds-cheatsheets Python 在数据科学方面使用库的速查表，包含了 Pandas、Jupyter、SQL、Dask 等。虽然都是些基本的 API 调用，但是用来备忘和速查足以。 scrapydweb# scrapydweb Scrapy 爬虫管理平台，支持：Scrapyd 集群管理、日志可视化、定时任务、邮件通知、移动端 UI 相关连接# HelloGithub]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Paper | Graph Convolution over Pruned Dependency Trees Improves Relation Extraction]]></title>
    <url>%2F2019%2F03%2F29%2FGraph%20Convolution%20over%20Pruned%20Dependency%20Trees%20Improves%20Relation%20Extraction%2F</url>
    <content type="text"><![CDATA[论文：Graph Convolution over Pruned Dependency Trees Improves Relation Extraction作者：Yuhao Zhang, Peng Qi, Christopher D. Manning时间：1809单位：Stanford University会议：EMNLP代码链接：无 摘要#123451.句子依赖树能够帮助关系提取模型捕获远距离关系。2.但是, 现有的基于依赖的模型要么过于激进地修剪依赖关系树, 从而忽略了关键信息 (例如否定), 要么由于难以在不同的树结构上并行化而在配置上效率低下。3.本文提出了一种为关系提取量身定制的图形卷积网络的扩展, 它能有效地同时将任意依赖结构上的信息汇集在一起。 3.1为了在最大限度地删除不相关内容的同时整合相关信息, 本文进一步将一种新的修剪策略应用于输入树, 方法是将单词紧跟在关系可能存在的两个实体之间的最短路径周围。4.由此产生的模型在大型TAC代价数据集上实现了最先进的性能, 优于现有序列和基于依赖的神经模型。通过详细的分析, 结果还表明该模型具有对序列模型的互补优势, 并将其结合起来, 进一步改善了最新的水平]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>Relation Extraction</tag>
        <tag>Graph Convolution Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux | 常用命令]]></title>
    <url>%2F2019%2F03%2F28%2Fcs_notes_linux%2F</url>
    <content type="text"><![CDATA[目录# 一、常用操作以及概念 快捷键 求助 1. –help 2. man 3. info 4. doc 关机 1. who 2. sync 3. shutdown PATH sudo 包管理工具 发行版 VIM 三个模式 GNU 开源协议 二、磁盘 磁盘接口 1. IDE 2. SATA 3. SCSI 4. SAS 磁盘的文件名 三、分区 分区表 1. MBR 2. GPT 开机检测程序 1. BIOS 2. UEFI 四、文件系统 分区与文件系统 组成 文件读取 磁盘碎片 block inode 目录 日志 挂载 目录配置 五、文件 文件属性 文件与目录的基本操作 1. ls 2. cd 3. mkdir 4. rmdir 5. touch 6. cp 7. rm 8. mv 修改权限 文件默认权限 目录的权限 链接 1. 实体链接 2. 符号链接 获取文件内容 1. cat 2. tac 3. more 4. less 5. head 6. tail 7. od 指令与文件搜索 1. which 2. whereis 3. locate 4. find 六、压缩与打包 压缩文件名 压缩指令 1. gzip 2. bzip2 3. xz 打包 七、Bash 特性 变量操作 指令搜索顺序 数据流重定向 八、管道指令 提取指令 排序指令 双向输出重定向 字符转换指令 分区指令 九、正则表达式 grep printf awk 十、进程管理 查看进程 1. ps 2. pstree 3. top 4. netstat 进程状态 SIGCHLD wait() waitpid() 孤儿进程 僵尸进程 参考资料 内网服务器ssh隧道：ssh -L 8800:localhost:8800 jhdai@10.108.17.105 一、常用操作以及概念#快捷键# Tab：命令和文件名补全； Ctrl+C：中断正在运行的程序； Ctrl+D：结束键盘输入（End Of File，EOF） 求助#1. –help#指令的基本用法与选项介绍。 2. man#man 是 manual 的缩写，将指令的具体信息显示出来。 当执行man date时，有 DATE(1) 出现，其中的数字代表指令的类型，常用的数字及其类型如下： 代号 类型 1 用户在 shell 环境中可以操作的指令或者可执行文件 5 配置文件 8 系统管理员可以使用的管理指令 3. info#info 与 man 类似，但是 info 将文档分成一个个页面，每个页面可以进行跳转。 4. doc#/usr/share/doc 存放着软件的一整套说明文件。 关机#1. who#在关机前需要先使用 who 命令查看有没有其它用户在线。 2. sync#为了加快对磁盘文件的读写速度，位于内存中的文件数据不会立即同步到磁盘上，因此关机之前需要先进行 sync 同步操作。 3. shutdown#12345# shutdown [-krhc] 时间 [信息]-k ： 不会关机，只是发送警告信息，通知所有在线的用户-r ： 将系统的服务停掉后就重新启动-h ： 将系统的服务停掉后就立即关机-c ： 取消已经在进行的 shutdown 指令内容 PATH#可以在环境变量 PATH 中声明可执行文件的路径，路径之间用 : 分隔。 1/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/dmtsai/.local/bin:/home/dmtsai/bin sudo#sudo 允许一般用户使用 root 可执行的命令，不过只有在 /etc/sudoers 配置文件中添加的用户才能使用该指令。 包管理工具#RPM 和 DPKG 为最常见的两类软件包管理工具： RPM 全称为 Redhat Package Manager，最早由 Red Hat 公司制定实施，随后被 GNU 开源操作系统接受并成为很多 Linux 系统 (RHEL) 的既定软件标准。 与 RPM 进行竞争的是基于 Debian 操作系统 (Ubuntu) 的 DEB 软件包管理工具 DPKG，全称为 Debian Package，功能方面与 RPM 相似。 YUM 基于 RPM，具有依赖管理功能，并具有软件升级的功能。 发行版#Linux 发行版是 Linux 内核及各种应用软件的集成版本。 基于的包管理工具 商业发行版 社区发行版 RPM Red Hat Fedora / CentOS DPKG Ubuntu Debian VIM 三个模式# 一般指令模式（Command mode）：VIM 的默认模式，可以用于移动游标查看内容； 编辑模式（Insert mode）：按下 “i” 等按键之后进入，可以对文本进行编辑； 指令列模式（Bottom-line mode）：按下 “:” 按键之后进入，用于保存退出等操作。 在指令列模式下，有以下命令用于离开或者保存文件。 命令 作用 :w 写入磁盘 :w! 当文件为只读时，强制写入磁盘。到底能不能写入，与用户对该文件的权限有关 :q 离开 :q! 强制离开不保存 :wq 写入磁盘后离开 :wq! 强制写入磁盘后离开 GNU#GNU 计划，译为革奴计划，它的目标是创建一套完全自由的操作系统，称为 GNU，其内容软件完全以 GPL 方式发布。其中 GPL 全称为 GNU 通用公共许可协议，包含了以下内容： 以任何目的运行此程序的自由； 再复制的自由； 改进此程序，并公开发布改进的自由。 开源协议# Choose an open source license 如何选择开源许可证？ 二、磁盘#磁盘接口#1. IDE#IDE（ATA）全称 Advanced Technology Attachment，接口速度最大为 133MB/s，因为并口线的抗干扰性太差，且排线占用空间较大，不利电脑内部散热，已逐渐被 SATA 所取代。 2. SATA#SATA 全称 Serial ATA，也就是使用串口的 ATA 接口，抗干扰性强，且对数据线的长度要求比 ATA 低很多，支持热插拔等功能。SATA-II 的接口速度为 300MiB/s，而新的 SATA-III 标准可达到 600MiB/s 的传输速度。SATA 的数据线也比 ATA 的细得多，有利于机箱内的空气流通，整理线材也比较方便。 3. SCSI#SCSI 全称是 Small Computer System Interface（小型机系统接口），经历多代的发展，从早期的 SCSI-II 到目前的 Ultra320 SCSI 以及 Fiber-Channel（光纤通道），接口型式也多种多样。SCSI 硬盘广为工作站级个人电脑以及服务器所使用，因此会使用较为先进的技术，如碟片转速 15000rpm 的高转速，且传输时 CPU 占用率较低，但是单价也比相同容量的 ATA 及 SATA 硬盘更加昂贵。 4. SAS#SAS（Serial Attached SCSI）是新一代的 SCSI 技术，和 SATA 硬盘相同，都是采取序列式技术以获得更高的传输速度，可达到 6Gb/s。此外也透过缩小连接线改善系统内部空间等。 磁盘的文件名#Linux 中每个硬件都被当做一个文件，包括磁盘。磁盘以磁盘接口类型进行命名，常见磁盘的文件名如下： IDE 磁盘：/dev/hd[a-d] SATA/SCSI/SAS 磁盘：/dev/sd[a-p] 其中文件名后面的序号的确定与系统检测到磁盘的顺序有关，而与磁盘所插入的插槽位置无关。 三、分区#分区表#磁盘分区表主要有两种格式，一种是限制较多的 MBR 分区表，一种是较新且限制较少的 GPT 分区表。 1. MBR#MBR 中，第一个扇区最重要，里面有主要开机记录（Master boot record, MBR）及分区表（partition table），其中主要开机记录占 446 bytes，分区表占 64 bytes。 分区表只有 64 bytes，最多只能存储 4 个分区，这 4 个分区为主分区（Primary）和扩展分区（Extended）。其中扩展分区只有一个，它使用其它扇区用记录额外的分区表，因此通过扩展分区可以分出更多分区，这些分区称为逻辑分区。 Linux 也把分区当成文件，分区文件的命名方式为：磁盘文件名 + 编号，例如 /dev/sda1。注意，逻辑分区的编号从 5 开始。 2. GPT#不同的磁盘有不同的扇区大小，例如 512 bytes 和最新磁盘的 4 k。GPT 为了兼容所有磁盘，在定义扇区上使用逻辑区块地址（Logical Block Address, LBA），LBA 默认大小为 512 bytes。 GPT 第 1 个区块记录了主要开机记录（MBR），紧接着是 33 个区块记录分区信息，并把最后的 33 个区块用于对分区信息进行备份。这 33 个区块第一个为 GPT 表头纪录，这个部份纪录了分区表本身的位置与大小和备份分区的位置，同时放置了分区表的校验码 (CRC32)，操作系统可以根据这个校验码来判断 GPT 是否正确。若有错误，可以使用备份分区进行恢复。 GPT 没有扩展分区概念，都是主分区，每个 LAB 可以分 4 个分区，因此总共可以分 4 * 32 = 128 个分区。 MBR 不支持 2.2 TB 以上的硬盘，GPT 则最多支持到 233 TB = 8 ZB。 开机检测程序#1. BIOS#BIOS（Basic Input/Output System，基本输入输出系统），它是一个固件（嵌入在硬件中的软件），BIOS 程序存放在断电后内容不会丢失的只读内存中。 BIOS 是开机的时候计算机执行的第一个程序，这个程序知道可以开机的磁盘，并读取磁盘第一个扇区的主要开机记录（MBR），由主要开机记录（MBR）执行其中的开机管理程序，这个开机管理程序会加载操作系统的核心文件。 主要开机记录（MBR）中的开机管理程序提供以下功能：选单、载入核心文件以及转交其它开机管理程序。转交这个功能可以用来实现了多重引导，只需要将另一个操作系统的开机管理程序安装在其它分区的启动扇区上，在启动开机管理程序时，就可以通过选单选择启动当前的操作系统或者转交给其它开机管理程序从而启动另一个操作系统。 下图中，第一扇区的主要开机记录（MBR）中的开机管理程序提供了两个选单：M1、M2，M1 指向了 Windows 操作系统，而 M2 指向其它分区的启动扇区，里面包含了另外一个开机管理程序，提供了一个指向 Linux 的选单。 安装多重引导，最好先安装 Windows 再安装 Linux。因为安装 Windows 时会覆盖掉主要开机记录（MBR），而 Linux 可以选择将开机管理程序安装在主要开机记录（MBR）或者其它分区的启动扇区，并且可以设置开机管理程序的选单。 2. UEFI#BIOS 不可以读取 GPT 分区表，而 UEFI 可以。 四、文件系统#分区与文件系统#对分区进行格式化是为了在分区上建立文件系统。一个分区通常只能格式化为一个文件系统，但是磁盘阵列等技术可以将一个分区格式化为多个文件系统。 组成#最主要的几个组成部分如下： inode：一个文件占用一个 inode，记录文件的属性，同时记录此文件的内容所在的 block 编号； block：记录文件的内容，文件太大时，会占用多个 block。 除此之外还包括： superblock：记录文件系统的整体信息，包括 inode 和 block 的总量、使用量、剩余量，以及文件系统的格式与相关信息等； block bitmap：记录 block 是否被使用的位域。 文件读取#对于 Ext2 文件系统，当要读取一个文件的内容时，先在 inode 中去查找文件内容所在的所有 block，然后把所有 block 的内容读出来。 而对于 FAT 文件系统，它没有 inode，每个 block 中存储着下一个 block 的编号。 磁盘碎片#指一个文件内容所在的 block 过于分散。 block#在 Ext2 文件系统中所支持的 block 大小有 1K，2K 及 4K 三种，不同的大小限制了单个文件和文件系统的最大大小。 大小 1KB 2KB 4KB 最大单一文件 16GB 256GB 2TB 最大文件系统 2TB 8TB 16TB 一个 block 只能被一个文件所使用，未使用的部分直接浪费了。因此如果需要存储大量的小文件，那么最好选用比较小的 block。 inode#inode 具体包含以下信息： 权限 (read/write/excute)； 拥有者与群组 (owner/group)； 容量； 建立或状态改变的时间 (ctime)； 最近一次的读取时间 (atime)； 最近修改的时间 (mtime)； 定义文件特性的旗标 (flag)，如 SetUID…； 该文件真正内容的指向 (pointer)。 inode 具有以下特点： 每个 inode 大小均固定为 128 bytes (新的 ext4 与 xfs 可设定到 256 bytes)； 每个文件都仅会占用一个 inode。 inode 中记录了文件内容所在的 block 编号，但是每个 block 非常小，一个大文件随便都需要几十万的 block。而一个 inode 大小有限，无法直接引用这么多 block 编号。因此引入了间接、双间接、三间接引用。间接引用是指，让 inode 记录的引用 block 块记录引用信息。 目录#建立一个目录时，会分配一个 inode 与至少一个 block。block 记录的内容是目录下所有文件的 inode 编号以及文件名。 可以看出文件的 inode 本身不记录文件名，文件名记录在目录中，因此新增文件、删除文件、更改文件名这些操作与目录的 w 权限有关。 日志#如果突然断电，那么文件系统会发生错误，例如断电前只修改了 block bitmap，而还没有将数据真正写入 block 中。 ext3/ext4 文件系统引入了日志功能，可以利用日志来修复文件系统。 挂载#挂载利用目录作为文件系统的进入点，也就是说，进入目录之后就可以读取文件系统的数据。 目录配置#为了使不同 Linux 发行版本的目录结构保持一致性，Filesystem Hierarchy Standard (FHS) 规定了 Linux 的目录结构。最基础的三个目录如下： / (root, 根目录) /usr (unix software resource)：所有系统默认软件都会安装到这个目录； /var (variable)：存放系统或程序运行过程中的数据文件。 五、文件#文件属性#用户分为三种：文件拥有者、群组以及其它人，对不同的用户有不同的文件权限。 使用 ls 查看一个文件时，会显示一个文件的信息，例如 drwxr-xr-x. 3 root root 17 May 6 00:14 .config，对这个信息的解释如下： drwxr-xr-x：文件类型以及权限，第 1 位为文件类型字段，后 9 位为文件权限字段 3：链接数 root：文件拥有者 root：所属群组 17：文件大小 May 6 00:14：文件最后被修改的时间 .config：文件名 常见的文件类型及其含义有： d：目录 -：文件 l：链接文件 9 位的文件权限字段中，每 3 个为一组，共 3 组，每一组分别代表对文件拥有者、所属群组以及其它人的文件权限。一组权限中的 3 位分别为 r、w、x 权限，表示可读、可写、可执行。 文件时间有以下三种： modification time (mtime)：文件的内容更新就会更新； status time (ctime)：文件的状态（权限、属性）更新就会更新； access time (atime)：读取文件时就会更新。 文件与目录的基本操作#1. ls#列出文件或者目录的信息，目录的信息就是其中包含的文件。 1234# ls [-aAdfFhilnrRSt] file|dir-a ：列出全部的文件-d ：仅列出目录本身-l ：以长数据串行列出，包含文件的属性与权限等等数据 2. cd#更换当前目录。 1cd [相对路径或绝对路径] 3. mkdir#创建目录。 123# mkdir [-mp] 目录名称-m ：配置目录权限-p ：递归创建目录 4. rmdir#删除目录，目录必须为空。 12rmdir [-p] 目录名称-p ：递归删除目录 5. touch#更新文件时间或者建立新文件。 123456# touch [-acdmt] filename-a ： 更新 atime-c ： 更新 ctime，若该文件不存在则不建立新文件-m ： 更新 mtime-d ： 后面可以接更新日期而不使用当前日期，也可以使用 --date="日期或时间"-t ： 后面可以接更新时间而不使用当前时间，格式为[YYYYMMDDhhmm] 6. cp#复制文件。 如果源文件有两个以上，则目的文件一定要是目录才行。 12345678cp [-adfilprsu] source destination-a ：相当于 -dr --preserve=all 的意思，至于 dr 请参考下列说明-d ：若来源文件为链接文件，则复制链接文件属性而非文件本身-i ：若目标文件已经存在时，在覆盖前会先询问-p ：连同文件的属性一起复制过去-r ：递归持续复制-u ：destination 比 source 旧才更新 destination，或 destination 不存在的情况下才复制--preserve=all ：除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了 7. rm#删除文件。 12# rm [-fir] 文件或目录-r ：递归删除 8. mv#移动文件。 123# mv [-fiu] source destination# mv [options] source1 source2 source3 .... directory-f ： force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 修改权限#可以将一组权限用数字来表示，此时一组权限的 3 个位当做二进制数字的位，从左到右每个位的权值为 4、2、1，即每个权限对应的数字权值为 r : 4、w : 2、x : 1。 1# chmod [-R] xyz dirname/filename 示例：将 .bashrc 文件的权限修改为 -rwxr-xr–。 1# chmod 754 .bashrc 也可以使用符号来设定权限。 12345678# chmod [ugoa] [+-=] [rwx] dirname/filename- u：拥有者- g：所属群组- o：其他人- a：所有人- +：添加权限- -：移除权限- =：设定权限 示例：为 .bashrc 文件的所有用户添加写权限。 1# chmod a+w .bashrc 文件默认权限# 文件默认权限：文件默认没有可执行权限，因此为 666，也就是 -rw-rw-rw- 。 目录默认权限：目录必须要能够进入，也就是必须拥有可执行权限，因此为 777 ，也就是 drwxrwxrwx。 可以通过 umask 设置或者查看文件的默认权限，通常以掩码的形式来表示，例如 002 表示其它用户的权限去除了一个 2 的权限，也就是写权限，因此建立新文件时默认的权限为 -rw-rw-r–。 目录的权限#文件名不是存储在一个文件的内容中，而是存储在一个文件所在的目录中。因此，拥有文件的 w 权限并不能对文件名进行修改。 目录存储文件列表，一个目录的权限也就是对其文件列表的权限。因此，目录的 r 权限表示可以读取文件列表；w 权限表示可以修改文件列表，具体来说，就是添加删除文件，对文件名进行修改；x 权限可以让该目录成为工作目录，x 权限是 r 和 w 权限的基础，如果不能使一个目录成为工作目录，也就没办法读取文件列表以及对文件列表进行修改了。 链接#123# ln [-sf] source_filename dist_filename-s ：默认是 hard link，加 -s 为 symbolic link-f ：如果目标文件存在时，先删除目标文件 1. 实体链接#在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。 删除任意一个条目，文件还是存在，只要引用数量不为 0。 有以下限制：不能跨越文件系统、不能对目录进行链接。 1234# ln /etc/crontab .# ll -i /etc/crontab crontab34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 crontab34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab 2. 符号链接#符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。 当源文件被删除了，链接文件就打不开了。 可以为目录建立链接。 123# ll -i /etc/crontab /root/crontab234474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab53745909 lrwxrwxrwx. 1 root root 12 Jun 23 22:31 /root/crontab2 -&gt; /etc/crontab 获取文件内容#1. cat#取得文件内容。 12# cat [-AbEnTv] filename-n ：打印出行号，连同空白行也会有行号，-b 不会 2. tac#是 cat 的反向操作，从最后一行开始打印。 3. more#和 cat 不同的是它可以一页一页查看文件内容，比较适合大文件的查看。 4. less#和 more 类似，但是多了一个向前翻页的功能。 5. head#取得文件前几行。 12# head [-n number] filename-n ：后面接数字，代表显示几行的意思 6. tail#是 head 的反向操作，只是取得是后几行。 7. od#以字符或者十六进制的形式显示二进制文件。 指令与文件搜索#1. which#指令搜索。 12# which [-a] command-a ：将所有指令列出，而不是只列第一个 2. whereis#文件搜索。速度比较快，因为它只搜索几个特定的目录。 1# whereis [-bmsu] dirname/filename 3. locate#文件搜索。可以用关键字或者正则表达式进行搜索。 locate 使用 /var/lib/mlocate/ 这个数据库来进行搜索，它存储在内存中，并且每天更新一次，所以无法用 locate 搜索新建的文件。可以使用 updatedb 来立即更新数据库。 12# locate [-ir] keyword-r：正则表达式 4. find#文件搜索。可以使用文件的属性和权限进行搜索。 12# find [basedir] [option]example: find . -name "shadow*" ① 与时间有关的选项 1234-mtime n ：列出在 n 天前的那一天修改过内容的文件-mtime +n ：列出在 n 天之前 (不含 n 天本身) 修改过内容的文件-mtime -n ：列出在 n 天之内 (含 n 天本身) 修改过内容的文件-newer file ： 列出比 file 更新的文件 ② 与文件拥有者和所属群组有关的选项 123456-uid n-gid n-user name-group name-nouser ：搜索拥有者不存在 /etc/passwd 的文件-nogroup：搜索所属群组不存在于 /etc/group 的文件 ③ 与文件权限和名称有关的选项 123456-name filename-size [+-]SIZE：搜寻比 SIZE 还要大 (+) 或小 (-) 的文件。这个 SIZE 的规格有：c: 代表 byte，k: 代表 1024bytes。所以，要找比 50KB 还要大的文件，就是 -size +50k-type TYPE-perm mode ：搜索权限等于 mode 的文件-perm -mode ：搜索权限包含 mode 的文件-perm /mode ：搜索权限包含任一 mode 的文件 六、压缩与打包#压缩文件名#Linux 底下有很多压缩文件名，常见的如下： 扩展名 压缩程序 *.Z compress *.zip zip *.gz gzip *.bz2 bzip2 *.xz xz *.tar tar 程序打包的数据，没有经过压缩 *.tar.gz tar 程序打包的文件，经过 gzip 的压缩 *.tar.bz2 tar 程序打包的文件，经过 bzip2 的压缩 *.tar.xz tar 程序打包的文件，经过 xz 的压缩 压缩指令#1. gzip#gzip 是 Linux 使用最广的压缩指令，可以解开 compress、zip 与 gzip 所压缩的文件。 经过 gzip 压缩过，源文件就不存在了。 有 9 个不同的压缩等级可以使用。 可以使用 zcat、zmore、zless 来读取压缩文件的内容。 123456$ gzip [-cdtv#] filename-c ：将压缩的数据输出到屏幕上-d ：解压缩-t ：检验压缩文件是否出错-v ：显示压缩比等信息-# ： # 为数字的意思，代表压缩等级，数字越大压缩比越高，默认为 6 2. bzip2#提供比 gzip 更高的压缩比。 查看命令：bzcat、bzmore、bzless、bzgrep。 12$ bzip2 [-cdkzv#] filename-k ：保留源文件 3. xz#提供比 bzip2 更佳的压缩比。 可以看到，gzip、bzip2、xz 的压缩比不断优化。不过要注意的是，压缩比越高，压缩的时间也越长。 查看命令：xzcat、xzmore、xzless、xzgrep。 1$ xz [-dtlkc#] filename 打包#压缩指令只能对一个文件进行压缩，而打包能够将多个文件打包成一个大文件。tar 不仅可以用于打包，也可以使用 gip、bzip2、xz 将打包文件进行压缩。 123456789101112$ tar [-z|-j|-J] [cv] [-f 新建的 tar 文件] filename... ==打包压缩$ tar [-z|-j|-J] [tv] [-f 已有的 tar 文件] ==查看$ tar [-z|-j|-J] [xv] [-f 已有的 tar 文件] [-C 目录] ==解压缩-z ：使用 zip；-j ：使用 bzip2；-J ：使用 xz；-c ：新建打包文件；-t ：查看打包文件里面有哪些文件；-x ：解打包或解压缩的功能；-v ：在压缩/解压缩的过程中，显示正在处理的文件名；-f : filename：要处理的文件；-C 目录 ： 在特定目录解压缩。 使用方式 命令 打包压缩 tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查 看 tar -jtv -f filename.tar.bz2 解压缩 tar -jxv -f filename.tar.bz2 -C 要解压缩的目录 七、Bash#可以通过 Shell 请求内核提供服务，Bash 正是 Shell 的一种。 特性# 命令历史：记录使用过的命令 命令与文件补全：快捷键：tab 命名别名：例如 lm 是 ls -al 的别名 shell scripts 通配符：例如 ls -l /usr/bin/X* 列出 /usr/bin 下面所有以 X 开头的文件 变量操作#对一个变量赋值直接使用 =。 对变量取用需要在变量前加上 \$ ，也可以用 \${} 的形式； 输出变量使用 echo 命令。 123$ x=abc$ echo $x$ echo $&#123;x&#125; 变量内容如果有空格，必须使用双引号或者单引号。 双引号内的特殊字符可以保留原本特性，例如 x=”lang is \$LANG”，则 x 的值为 lang is zh_TW.UTF-8； 单引号内的特殊字符就是特殊字符本身，例如 x=’lang is \$LANG’，则 x 的值为 lang is \$LANG。 可以使用 `指令` 或者 \$(指令) 的方式将指令的执行结果赋值给变量。例如 version=\$(uname -r)，则 version 的值为 4.15.0-22-generic。 可以使用 export 命令将自定义变量转成环境变量，环境变量可以在子程序中使用，所谓子程序就是由当前 Bash 而产生的子 Bash。 Bash 的变量可以声明为数组和整数数字。注意数字类型没有浮点数。如果不进行声明，默认是字符串类型。变量的声明使用 declare 命令： 12345$ declare [-aixr] variable-a ： 定义为数组类型-i ： 定义为整数类型-x ： 定义为环境变量-r ： 定义为 readonly 类型 使用 [ ] 来对数组进行索引操作： 123$ array[1]=a$ array[2]=b$ echo $&#123;array[1]&#125; 指令搜索顺序# 以绝对或相对路径来执行指令，例如 /bin/ls 或者 ./ls ； 由别名找到该指令来执行； 由 Bash 内置的指令来执行； 按 \$PATH 变量指定的搜索路径的顺序找到第一个指令来执行。 数据流重定向#重定向指的是使用文件代替标准输入、标准输出和标准错误输出。 1 代码 运算符 标准输入 (stdin) 0 &lt; 或 &lt;&lt; 标准输出 (stdout) 1 &gt; 或 &gt;&gt; 标准错误输出 (stderr) 2 2&gt; 或 2&gt;&gt; 其中，有一个箭头的表示以覆盖的方式重定向，而有两个箭头的表示以追加的方式重定向。 可以将不需要的标准输出以及标准错误输出重定向到 /dev/null，相当于扔进垃圾箱。 如果需要将标准输出以及标准错误输出同时重定向到一个文件，需要将某个输出转换为另一个输出，例如 2&gt;&amp;1 表示将标准错误输出转换为标准输出。 1$ find /home -name .bashrc &gt; list 2&gt;&amp;1 八、管道指令#管道是将一个命令的标准输出作为另一个命令的标准输入，在数据需要经过多个步骤的处理之后才能得到我们想要的内容时就可以使用管道。 在命令之间使用 | 分隔各个管道命令。 1$ ls -al /etc | less 提取指令#cut 对数据进行切分，取出想要的部分。 切分过程一行一行地进行。 1234$ cut-d ：分隔符-f ：经过 -d 分隔后，使用 -f n 取出第 n 个区间-c ：以字符为单位取出区间 示例 1：last 显示登入者的信息，取出用户名。 123456$ lastroot pts/1 192.168.201.101 Sat Feb 7 12:35 still logged inroot pts/1 192.168.201.101 Fri Feb 6 12:13 - 18:46 (06:33)root pts/1 192.168.201.254 Thu Feb 5 22:37 - 23:53 (01:16)$ last | cut -d ' ' -f 1 示例 2：将 export 输出的信息，取出第 12 字符以后的所有字符串。 12345678$ exportdeclare -x HISTCONTROL="ignoredups"declare -x HISTSIZE="1000"declare -x HOME="/home/dmtsai"declare -x HOSTNAME="study.centos.vbird".....(其他省略).....$ export | cut -c 12- 排序指令#sort 用于排序。 123456789$ sort [-fbMnrtuk] [file or stdin]-f ：忽略大小写-b ：忽略最前面的空格-M ：以月份的名字来排序，例如 JAN，DEC-n ：使用数字-r ：反向排序-u ：相当于 unique，重复的内容只出现一次-t ：分隔符，默认为 tab-k ：指定排序的区间 示例：/etc/passwd 文件内容以 : 来分隔，要求以第三列进行排序。 12345$ cat /etc/passwd | sort -t ':' -k 3root:x:0:0:root:/root:/bin/bashdmtsai:x:1000:1000:dmtsai:/home/dmtsai:/bin/bashalex:x:1001:1002::/home/alex:/bin/basharod:x:1002:1003::/home/arod:/bin/bash uniq 可以将重复的数据只取一个。 123$ uniq [-ic]-i ：忽略大小写-c ：进行计数 示例：取得每个人的登录总次数 1234567$ last | cut -d ' ' -f 1 | sort | uniq -c16 (unknown47 dmtsai4 reboot7 root1 wtmp 双向输出重定向#输出重定向会将输出内容重定向到文件中，而 tee 不仅能够完成这个功能，还能保留屏幕上的输出。也就是说，使用 tee 指令，一个输出会同时传送到文件和屏幕上。 1$ tee [-a] file 字符转换指令#tr 用来删除一行中的字符，或者对字符进行替换。 12$ tr [-ds] SET1 ...-d ： 删除行中 SET1 这个字符串 示例，将 last 输出的信息所有小写转换为大写。 1$ last | tr '[a-z]' '[A-Z]' col 将 tab 字符转为空格字符。 12$ col [-xb]-x ： 将 tab 键转换成对等的空格键 expand 将 tab 转换一定数量的空格，默认是 8 个。 12$ expand [-t] file-t ：tab 转为空格的数量 join 将有相同数据的那一行合并在一起。 12345$ join [-ti12] file1 file2-t ：分隔符，默认为空格-i ：忽略大小写的差异-1 ：第一个文件所用的比较字段-2 ：第二个文件所用的比较字段 paste 直接将两行粘贴在一起。 12$ paste [-d] file1 file2-d ：分隔符，默认为 tab 分区指令#split 将一个文件划分成多个文件。 1234$ split [-bl] file PREFIX-b ：以大小来进行分区，可加单位，例如 b, k, m 等-l ：以行数来进行分区。- PREFIX ：分区文件的前导名称 九、正则表达式#grep#g/re/p（globally search a regular expression and print)，使用正则表示式进行全局查找并打印。 123456$ grep [-acinv] [--color=auto] 搜寻字符串 filename-c ： 统计个数-i ： 忽略大小写-n ： 输出行号-v ： 反向选择，也就是显示出没有 搜寻字符串 内容的那一行--color=auto ：找到的关键字加颜色显示 示例：把含有 the 字符串的行提取出来（注意默认会有 –color=auto 选项，因此以下内容在 Linux 中有颜色显示 the 字符串） 123456$ grep -n 'the' regular_express.txt8:I can't finish the test.12:the symbol '*' is represented as start.15:You are the best is mean you are the no. 1.16:The world Happy is the same with "glad".18:google is the best tools for search keyword 因为 { 和 } 在 shell 是有特殊意义的，因此必须要使用转义字符进行转义。 1$ grep -n 'go\&#123;2,5\&#125;g' regular_express.txt printf#用于格式化输出。它不属于管道命令，在给 printf 传数据时需要使用 $( ) 形式。 1234$ printf '%10s %5i %5i %5i %8.2f \n' $(cat printf.txt) DmTsai 80 60 92 77.33 VBird 75 55 80 70.00 Ken 60 90 70 73.33 awk#是由 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 创造，awk 这个名字就是这三个创始人名字的首字母。 awk 每次处理一行，处理的最小单位是字段，每个字段的命名方式为：\$n，n 为字段号，从 1 开始，\$0 表示一整行。 示例：取出最近五个登录用户的用户名和 IP 123456$ last -n 5dmtsai pts/0 192.168.1.100 Tue Jul 14 17:32 still logged indmtsai pts/0 192.168.1.100 Thu Jul 9 23:36 - 02:58 (03:22)dmtsai pts/0 192.168.1.100 Thu Jul 9 17:23 - 23:36 (06:12)dmtsai pts/0 192.168.1.100 Thu Jul 9 08:02 - 08:17 (00:14)dmtsai tty1 Fri May 29 11:55 - 12:11 (00:15) 1$ last -n 5 | awk '&#123;print $1 "\t" $3&#125;' 可以根据字段的某些条件进行匹配，例如匹配字段小于某个值的那一行数据。 1$ awk '条件类型 1 &#123;动作 1&#125; 条件类型 2 &#123;动作 2&#125; ...' filename 示例：/etc/passwd 文件第三个字段为 UID，对 UID 小于 10 的数据进行处理。 1234$ cat /etc/passwd | awk &apos;BEGIN &#123;FS=&quot;:&quot;&#125; $3 &lt; 10 &#123;print $1 &quot;\t &quot; $3&#125;&apos;root 0bin 1daemon 2 awk 变量： 变量名称 代表意义 NF 每一行拥有的字段总数 NR 目前所处理的是第几行数据 FS 目前的分隔字符，默认是空格键 示例：显示正在处理的行号以及每一行有多少字段 123456$ last -n 5 | awk '&#123;print $1 "\t lines: " NR "\t columns: " NF&#125;'dmtsai lines: 1 columns: 10dmtsai lines: 2 columns: 10dmtsai lines: 3 columns: 10dmtsai lines: 4 columns: 10dmtsai lines: 5 columns: 9 十、进程管理#查看进程#1. ps#查看某个时间点的进程信息 示例一：查看自己的进程 1# ps -l 示例二：查看系统所有进程 1# ps aux 示例三：查看特定的进程 1# ps aux | grep threadx 2. pstree#查看进程树 示例：查看所有进程树 1# pstree -A 3. top#实时显示进程信息 示例：两秒钟刷新一次 1# top -d 2 4. netstat#查看占用端口的进程 示例：查看特定端口的进程 1# netstat -anp | grep port 进程状态# 状态 说明 R running or runnable (on run queue) D uninterruptible sleep (usually I/O) S interruptible sleep (waiting for an event to complete) Z zombie (terminated but not reaped by its parent) T stopped (either by a job control signal or because it is being traced) SIGCHLD#当一个子进程改变了它的状态时（停止运行，继续运行或者退出），有两件事会发生在父进程中： 得到 SIGCHLD 信号； waitpid() 或者 wait() 调用会返回。 其中子进程发送的 SIGCHLD 信号包含了子进程的信息，比如进程 ID、进程状态、进程使用 CPU 的时间等。 在子进程退出时，它的进程描述符不会立即释放，这是为了让父进程得到子进程信息，父进程通过 wait() 和 waitpid() 来获得一个已经退出的子进程的信息。 wait()#1pid_t wait(int *status) 父进程调用 wait() 会一直阻塞，直到收到一个子进程退出的 SIGCHLD 信号，之后 wait() 函数会销毁子进程并返回。 如果成功，返回被收集的子进程的进程 ID；如果调用进程没有子进程，调用就会失败，此时返回 -1，同时 errno 被置为 ECHILD。 参数 status 用来保存被收集的子进程退出时的一些状态，如果对这个子进程是如何死掉的毫不在意，只想把这个子进程消灭掉，可以设置这个参数为 NULL。 waitpid()#1pid_t waitpid(pid_t pid, int *status, int options) 作用和 wait() 完全相同，但是多了两个可由用户控制的参数 pid 和 options。 pid 参数指示一个子进程的 ID，表示只关心这个子进程退出的 SIGCHLD 信号。如果 pid=-1 时，那么和 wait() 作用相同，都是关心所有子进程退出的 SIGCHLD 信号。 options 参数主要有 WNOHANG 和 WUNTRACED 两个选项，WNOHANG 可以使 waitpid() 调用变成非阻塞的，也就是说它会立即返回，父进程可以继续执行其它任务。 孤儿进程#一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。 孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。 由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。 僵尸进程#一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。 僵尸进程通过 ps 命令显示出来的状态为 Z（zombie）。 系统所能使用的进程号是有限的，如果产生大量僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。 要消灭系统中大量的僵尸进程，只需要将其父进程杀死，此时僵尸进程就会变成孤儿进程，从而被 init 所收养，这样 init 就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程。 参考资料# Linux 命令手册 Linux 百度脑图]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Environment | Hexo+GitPages 配置]]></title>
    <url>%2F2019%2F03%2F28%2Fenvironment_hexo_gitpages%2F</url>
    <content type="text"><![CDATA[目录# 缘起 摘要 Hexo 部分 本地环境 基本操作 GitPages 简介 创建账户 创建仓库 添加SSH Key 本地Hexo部署到Github 个性化配置 站点配置文件_config.yml 主题配置文件_config.yml 支持markdown目录 添加进度条 添加RSS 统计字符+阅读时间 PDF 自定义文章排序 文章末尾统一添加“本文结束”标记 相关链接 缘起#网上的教程非常多，但遇到问题总是要找很久才能解决，于是想要自己总结一下。 摘要#本文从Hexo和Github两部分总结关于GitPages部署个人博客以及相关的配置，一是为了自己防止重新搭建时忘记在网上浪费太多时间；二是为了帮助更多新手少走弯路，节约时间，最后将常用的基本配置总结了一下，总结的配置并不全面，但是基本需求满足了。 Hexo 部分# hexo 官网 hexo 文档 hexo themes 本地环境# git node hexo（sudo npm install -g hexo） 基本操作#12345678910mkdir blogcd bloghexo helphexo versionhexo init hexo new 'Hello' 新建文章hexo new page 'pageName'新建页面hexo generate|ghexo server|s浏览器访问:http://localhost:4000 GitPages 简介# github pages 创建账户# 官网：github ,假设账户名为username 创建仓库# 创建公开的仓库,假设为username.github.io 添加SSH Key#注意 如果在部署时遇到权限问题，很有可能是因为没有添加ssh key.123ssh-keygen -C "your email"cat ~/.ssh/id_rsa.pub 复制到剪切板打开github -&gt; setting -&gt; SSH Key -&gt; add ssh-key 粘贴 本地Hexo部署到Github#12345npm install hexo-deployer-git --save (如果报错:Deployer not found :git就是没有执行改命令)hexo cleanhexo ghexo d成功部署即可访问username.github.io 个性化配置#站点配置文件_config.yml# 这里是我的配置文件，大体上功能和英文名字对应，容易理解，默认的地方没有修改，中文注释的地方可以自由修改。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# Site 网站基础配置title: Jhai.Dai's Blogsubtitle: 不积跬步无以至千里，不积小流无以成江海description: 山不在高有仙则灵,水不在深有龙则灵keywords:author: Jhai.Daiemail: user@gmail.comlanguage: zh-CNtimezone: Asia/Shanghai# URL #这项暂不配置，绑定域名后，欲创建sitemap.xml需要配置该项url: https://username.github.ioroot: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render: README.md # Writing new_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: true #资源文件夹，比如图片、视频等relative_link: falsefuture: truehighlight: enable: true backtick_code_block: true line_number: true auto_detect: true tab_replace: # Home page settingindex_generator: path: '' per_page: 10 order_by: -date # Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination 每页显示文章数，可以自定义，贴主设置的是10per_page: 10pagination_dir: page# Extensions 这里配置站点所用主题和插件，暂时默认theme: next# Deployment 部署配置deploy: type: git repository: git@github.com:username/username.github.io.git branch: master 主题配置文件_config.yml#1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586871.网站logofavicon: small: /images/favicon-16x16-next.png medium: /images/favicon-32x32-next.png2.github 彩带github_banner: enable: true permalink: https://github.com/username3.菜单以tags为例，tags是标签，/tags表示路径，位于:source/tags，||后面的tags表示 hexo使用的图标(名字要在FontAwsome库中存在才行)，配置好之后要创建对应的目录结构：hexo new page "tags"menu: home: / || home //主页 archives: /archives/ || archive //归档 categories: /categories/ || th //分类 tags: /tags/ || tags //标签 about: /about/ || user //关于 #resources: /resources || download //资源 #schedule: /schedule/ || calendar //日程表 #sitemap: /sitemap.xml || sitemap //站点地图 commonweal: /404.html || heartbeat //公益404menu_settings: icons: true #设置成true 显示图片4.社交账号social: GitHub: https://github.com/jasonhavend || github E-Mail: mailto:jhai.dear@gmail.com || envelope Weibo: https://weibo.com/5338420153/info || weibo #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twittersocial_icons: enable: true #开启图标5.头像avatar: url: /images/avatar.jpg #图片位置在themes/主题/source/images/6.文章目录toc: enable: true number: true max_depth: 67.侧边栏sidebar: position: left display: post8.返回顶端back2top: enable: true9.文本对齐text_align: desktop: justify mobile: justify10.首页文章显示摘要auto_excerpt: enable: true length: 150 # 截取长度为150个字符11.阅读更多read_more_btn: true12.支付奖励reward: #wechatpay: /images/wechatpay.png #alipay: /images/alipay.png #bitcoin: /images/bitcoin.png13.高亮模式highlight_theme: normal14.数学渲染支持math: enable: true15.是否支持分享likely: enable: false16.站内搜索local_search: enable: false17.显示阅读次数busuanzi_count: enable: true total_visitors: true18.评论插件gitalk: enable: true githubID: github帐号 # 例：123 repo: 仓库名称 # 例：123.github.io ClientID: Client ID ClientSecret: Client Secret adminUser: github帐号 #指定可初始化评论账户 distractionFreeMode: true19.修改文章底部的那个带#号的标签修改模板 /themes/next/layout/_macro/post.swig，搜索 rel="tag"&gt;#，将 # 换成&lt;i class="fa fa-tag"&gt;&lt;/i&gt; 支持markdown目录#1234567891011121314首先，安装一个hexo-toc的插件npm install hexo-toc --save然后，配置一下站点配置文件_config.yml:toc: maxdepth: 3 class: toc slugify: transliteration decodeEntities: false anchor: position: after symbol: '#' style: header-anchor在Markdown文章中加入TOC的占位符：&lt;!-- toc --&gt; 添加进度条#12345678910111213141516hexo-path&#125;/themes/next/layout/_partials/head/head.swig中顶部加入如下代码&lt;script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"&gt;&lt;/script&gt;&lt;link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet"&gt;&lt;style&gt;.pace .pace-progress &#123; background: #f6a427; /*进度条颜色*/ height: 3px;&#125;.pace .pace-progress-inner &#123; box-shadow: 0 0 10px #1E92FB, 0 0 5px #1E92FB; /*阴影颜色*/&#125;.pace .pace-activity &#123; border-top-color: #1E92FB; /*上边框颜色*/ border-left-color: #1E92FB; /*左边框颜色*/&#125;&lt;/style&gt; 添加RSS#12345678安装npm install --save hexo-generator-feed站点_config.yml文件pligins: hexo-generator-feed主题_config.yml文件rss: /atom.xml 统计字符+阅读时间#12345678910111213141516171819202122安装npm install hexo-symbols-count-time --save修改 站点_config.yml文件symbols_count_time: #文章内是否显示 symbols: true time: true # 网页底部是否显示 total_symbols: true total_time: true修改 主题_config.yml文件symbols_count_time: separated_meta: true #文章中的显示是否显示文字（本文字数|阅读时长） item_text_post: true #网页底部的显示是否显示文字（站点总字数|站点阅读时长） item_text_total: false # Average Word Length (chars count in word) awl: 4 # Words Per Minute wpm: 275 PDF#1参考 https://blog.csdn.net/wugenqiang/article/details/88377669 自定义文章排序#12默认是按照时间顺序参考 https://www.jianshu.com/p/42a4efcdf8d7 文章末尾统一添加“本文结束”标记#123456789101112在路径 \themes\next\layout\_macro 中新建 passage-end-tag.swig 文件,并添加以下内容：&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style="text-align:center;color: #ccc;font-size:20px;"&gt;-------------&amp;nbsp;本文结束&amp;nbsp;&amp;nbsp;&lt;i class="fa fa-paw"&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;感谢您的阅读&amp;nbsp;-------------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt;打开\themes\next\layout\_macro\post.swig文件，在post-body 之后， post-footer 之前添加如下内容：&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'passage-end-tag.swig' %&#125; &#123;% endif %&#125;&lt;/div&gt; 相关链接# hexo 官网 github 官网 node 官网 FontAwsome 中文网 个性化Hexo]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
